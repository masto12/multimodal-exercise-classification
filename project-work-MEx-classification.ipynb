{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-708d46d3f9180abe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Multimodal Data Fusion - Project Work: Multi-Modal Physical Exercise Classification\n",
    "\n",
    "\n",
    "In this project, real multi-modal data is studied by utilizing different techniques presented during the course. Open MEx dataset from UCI machine learning repository is used. Idea is to apply different techniques to recognize physical exercises from wearable sensors, pressure mat and depth camera, user-independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "Add your information here\n",
    "\n",
    "Name: Martti Ilvesm√§ki\n",
    "\n",
    "Student number:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32738734cf6f1a4f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Description \n",
    "\n",
    "The goal of this project is to develop user-independent pre-processing and classification models to recognize 7 different physical exercises measured by accelerometers (attached to subject's thigh and wrist), pressure mat and depth camera (above the subject facing downwards recording an aerial view). All the exercises were performed subject lying down on the mat. There are totally 30 subjects in the  dataset, and in this work 25 persons is used as training and validation. Remaining 5 subjects has been given without subject or exercise IDs. Your work is to experiment different fusion methods and exercise classification. Detailed description of the dataset and original data can be access in [MEx dataset @ UCI machine learning repository](https://archive.ics.uci.edu/ml/datasets/MEx#). We are providing the preprocessed dataset in Moodle.\n",
    "\n",
    "The project work is divided on following phases:\n",
    "\n",
    "1. Data exploration and visualization\n",
    "2. Data preprocessing and feature extraction\n",
    "3. Feature selection, fusion and model development and evaluation\n",
    "4. Prediction of the held out test set\n",
    "\n",
    "You are free to use libraries to do the tasks, for example scikit-learn numpy, matplotlib, etc.. In each phase, you should visualize and analyse the results and document the work to a <b>min 3 - max 10 page report </b>. Nice looking and informative report representing your results and analysis will be part of the grading in addition to actual implementation. Return the notebook together with your report as pdf in Moodle.\n",
    "\n",
    "The results are validated using confusion matrices and F1 scores. F1 macro score is given as \n",
    "<br>\n",
    "<br>\n",
    "$\n",
    "\\begin{equation}\n",
    "F1_{macro} = \\frac{1}{N} \\sum_i^N F1_i,\n",
    "\\end{equation}\n",
    "$\n",
    "<br>\n",
    "<br>\n",
    "where $F1_i = 2  \\frac{precision_i * recall_i}{precision_i + recall_i}$, and $N$ is the number of classes.\n",
    "<br>\n",
    "\n",
    "## Overview of the data\n",
    "\n",
    "The MEx dataset has been preprocessed into feature files ready for machine learning. The preprocessing extracts statistical features from multi-modal sensor data using sliding time windows and aggregating the information. After feature extraction the data rows (windows) has been shuffled randomly.\n",
    "\n",
    "### Data Files Provided\n",
    "\n",
    "#### 1. **mex_features_train.csv**\n",
    "- **Purpose**: Training and validation dataset with labels (exercise ID)\n",
    "- **Size**: 25 subjects\n",
    "- **Subject IDs**: Renumbered from 1 to 25 (anonymized, not original IDs)\n",
    "- **Contains**: `subject_id`, `exercise`, and all feature columns\n",
    "\n",
    "\n",
    "#### 2. **mex_features_test_no_labels.csv**\n",
    "- **Purpose**: Test dataset without labels\n",
    "- **Size**: 5 subjects, same features as mex_features_train.csv\n",
    "- **Contains**: ONLY feature columns (no `subject_id` or `exercise`)\n",
    "- **Use**: Make predictions to data from this file at task 4. <b> DO NOT USE THIS DATA BEFORE TASK 4. </b>\n",
    "\n",
    "## Data Structure\n",
    "\n",
    "### Key Columns\n",
    "\n",
    "1. **subject_id** (only in train data)\n",
    "   - Training: Values 1-25 (renumbered for anonymization)\n",
    "\n",
    "2. **exercise** (only in train data)\n",
    "   - Values: 1-7\n",
    "\n",
    "3. **Feature columns** (same in all files)\n",
    "   - Accelerometer features: min,max,mean,std for each axis. ACT = Accelerometer in thigh, ACW = Accelerometer in wrist \n",
    "   - Depth camera features: Pixel level mean and std from 12x16 image in vectorized form\n",
    "   - Pressure mat features: Mean and std from 32x16 pressure mat in vectorized form\n",
    "\n",
    "## Learning goals \n",
    "\n",
    "After the project work, you should  \n",
    "\n",
    "- be able to study real world multi-modal data\n",
    "- be able to apply different data fusion techniques to real-world problem\n",
    "- be able to evaluate the results\n",
    "- be able to analyse the outcome\n",
    "- be able to document your work properly\n",
    "\n",
    "## Relevant lectures\n",
    "\n",
    "Lectures 1-8\n",
    "\n",
    "## Relevant exercises\n",
    "\n",
    "Exercises 0-6\n",
    "\n",
    "## Relevant chapters in course book\n",
    "\n",
    "Chapter 1-14\n",
    "\n",
    "## Additional Material \n",
    "\n",
    "* Original dataset [MEx dataset @ UCI machine learning repository](https://archive.ics.uci.edu/ml/datasets/MEx#)\n",
    "* Related scientific article [MEx: Multi-modal Exercises Dataset for Human Activity Recognition](https://arxiv.org/pdf/1908.08992.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e096db2d9e8c24e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# 1. Data exploration and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Task 1.</b> (3 Points)\n",
    "\n",
    "Download the preprocessed data from Moodle. Example code for loading and filtering modalities is provided below.\n",
    "\n",
    "**Your task:** Explore the dataset and create informative visualizations for your report. Consider the characteristics of each modality, class distributions, data balance, and patterns that might be relevant for classification. Choose visualizations that best communicate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data shape: (4923, 1434)\n",
      "\n",
      "1. Accelerometer ACT columns (12 features):\n",
      "   ['act_x_mean', 'act_x_std', 'act_x_min', 'act_x_max', 'act_y_mean', 'act_y_std', 'act_y_min', 'act_y_max', 'act_z_mean', 'act_z_std', 'act_z_min', 'act_z_max']\n",
      "2. Accelerometer ACW columns (12 features):\n",
      "   ['acw_x_mean', 'acw_x_std', 'acw_x_min', 'acw_x_max', 'acw_y_mean', 'acw_y_std', 'acw_y_min', 'acw_y_max', 'acw_z_mean', 'acw_z_std', 'acw_z_min', 'acw_z_max']\n",
      "3. Pressure Mat columns (Only first five, total 1024 features):\n",
      "   ['pressure_mat_pixel_0_mean', 'pressure_mat_pixel_0_std', 'pressure_mat_pixel_1_mean', 'pressure_mat_pixel_1_std', 'pressure_mat_pixel_2_mean'] ...\n",
      "4. Depth Camera columns (Only first five, total 384 features):\n",
      "   ['depth_pixel_0_mean', 'depth_pixel_0_std', 'depth_pixel_1_mean', 'depth_pixel_1_std', 'depth_pixel_2_mean'] ...\n",
      "\n",
      "Example: Extract only depth camera std features\n",
      "Number of depth camera std features: 192\n",
      "First 5: ['depth_pixel_0_std', 'depth_pixel_1_std', 'depth_pixel_2_std', 'depth_pixel_3_std', 'depth_pixel_4_std']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('mex_features_train.csv')\n",
    "print(f\"\\nTraining data shape: {train_df.shape}\")\n",
    "\n",
    "# Filtering the modalities\n",
    "acc_act_cols = [col for col in train_df.columns if col.startswith('act_')]\n",
    "acc_acw_cols = [col for col in train_df.columns if col.startswith('acw_')]\n",
    "pressure_cols = [col for col in train_df.columns if col.startswith('pressure_mat_')]\n",
    "depth_cols = [col for col in train_df.columns if col.startswith('depth_')]\n",
    "print(f\"\\n1. Accelerometer ACT columns ({len(acc_act_cols)} features):\")\n",
    "print(f\"   {acc_act_cols}\")\n",
    "print(f\"2. Accelerometer ACW columns ({len(acc_acw_cols)} features):\")\n",
    "print(f\"   {acc_acw_cols}\")\n",
    "print(f\"3. Pressure Mat columns (Only first five, total {len(pressure_cols)} features):\")\n",
    "print(f\"   {pressure_cols[:5]} ...\")\n",
    "print(f\"4. Depth Camera columns (Only first five, total {len(depth_cols)} features):\")\n",
    "print(f\"   {depth_cols[:5]} ...\")\n",
    "\n",
    "# Example: Extract only depth camera std features\n",
    "print(\"\\nExample: Extract only depth camera std features\")\n",
    "depth_std_cols = [col for col in depth_cols if '_std' in col]\n",
    "print(f\"Number of depth camera std features: {len(depth_std_cols)}\")\n",
    "print(f\"First 5: {depth_std_cols[:5]}\")\n",
    "# Plot the first image from depth camera std\n",
    "depth_std_example = train_df[depth_std_cols].iloc[0].values\n",
    "depth_std_image = depth_std_example.reshape(12, 16)\n",
    "plt.imshow(depth_std_image, cmap='viridis', aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject_id', 'exercise', 'act_x_mean', 'act_x_std', 'act_x_min', 'act_x_max', 'act_y_mean', 'act_y_std', 'act_y_min', 'act_y_max', 'act_z_mean', 'act_z_std', 'act_z_min', 'act_z_max', 'acw_x_mean', 'acw_x_std', 'acw_x_min', 'acw_x_max', 'acw_y_mean', 'acw_y_std', 'acw_y_min', 'acw_y_max', 'acw_z_mean', 'acw_z_std', 'acw_z_min', 'acw_z_max', 'pressure_mat_pixel_0_mean', 'pressure_mat_pixel_0_std', 'pressure_mat_pixel_1_mean', 'pressure_mat_pixel_1_std', 'pressure_mat_pixel_2_mean', 'pressure_mat_pixel_2_std', 'pressure_mat_pixel_3_mean', 'pressure_mat_pixel_3_std', 'pressure_mat_pixel_4_mean', 'pressure_mat_pixel_4_std', 'pressure_mat_pixel_5_mean', 'pressure_mat_pixel_5_std', 'pressure_mat_pixel_6_mean', 'pressure_mat_pixel_6_std', 'pressure_mat_pixel_7_mean', 'pressure_mat_pixel_7_std', 'pressure_mat_pixel_8_mean', 'pressure_mat_pixel_8_std', 'pressure_mat_pixel_9_mean', 'pressure_mat_pixel_9_std', 'pressure_mat_pixel_10_mean', 'pressure_mat_pixel_10_std', 'pressure_mat_pixel_11_mean', 'pressure_mat_pixel_11_std', 'pressure_mat_pixel_12_mean', 'pressure_mat_pixel_12_std', 'pressure_mat_pixel_13_mean', 'pressure_mat_pixel_13_std', 'pressure_mat_pixel_14_mean', 'pressure_mat_pixel_14_std', 'pressure_mat_pixel_15_mean', 'pressure_mat_pixel_15_std', 'pressure_mat_pixel_16_mean', 'pressure_mat_pixel_16_std', 'pressure_mat_pixel_17_mean', 'pressure_mat_pixel_17_std', 'pressure_mat_pixel_18_mean', 'pressure_mat_pixel_18_std', 'pressure_mat_pixel_19_mean', 'pressure_mat_pixel_19_std', 'pressure_mat_pixel_20_mean', 'pressure_mat_pixel_20_std', 'pressure_mat_pixel_21_mean', 'pressure_mat_pixel_21_std', 'pressure_mat_pixel_22_mean', 'pressure_mat_pixel_22_std', 'pressure_mat_pixel_23_mean', 'pressure_mat_pixel_23_std', 'pressure_mat_pixel_24_mean', 'pressure_mat_pixel_24_std', 'pressure_mat_pixel_25_mean', 'pressure_mat_pixel_25_std', 'pressure_mat_pixel_26_mean', 'pressure_mat_pixel_26_std', 'pressure_mat_pixel_27_mean', 'pressure_mat_pixel_27_std', 'pressure_mat_pixel_28_mean', 'pressure_mat_pixel_28_std', 'pressure_mat_pixel_29_mean', 'pressure_mat_pixel_29_std', 'pressure_mat_pixel_30_mean', 'pressure_mat_pixel_30_std', 'pressure_mat_pixel_31_mean', 'pressure_mat_pixel_31_std', 'pressure_mat_pixel_32_mean', 'pressure_mat_pixel_32_std', 'pressure_mat_pixel_33_mean', 'pressure_mat_pixel_33_std', 'pressure_mat_pixel_34_mean', 'pressure_mat_pixel_34_std', 'pressure_mat_pixel_35_mean', 'pressure_mat_pixel_35_std', 'pressure_mat_pixel_36_mean', 'pressure_mat_pixel_36_std', 'pressure_mat_pixel_37_mean', 'pressure_mat_pixel_37_std', 'pressure_mat_pixel_38_mean', 'pressure_mat_pixel_38_std', 'pressure_mat_pixel_39_mean', 'pressure_mat_pixel_39_std', 'pressure_mat_pixel_40_mean', 'pressure_mat_pixel_40_std', 'pressure_mat_pixel_41_mean', 'pressure_mat_pixel_41_std', 'pressure_mat_pixel_42_mean', 'pressure_mat_pixel_42_std', 'pressure_mat_pixel_43_mean', 'pressure_mat_pixel_43_std', 'pressure_mat_pixel_44_mean', 'pressure_mat_pixel_44_std', 'pressure_mat_pixel_45_mean', 'pressure_mat_pixel_45_std', 'pressure_mat_pixel_46_mean', 'pressure_mat_pixel_46_std', 'pressure_mat_pixel_47_mean', 'pressure_mat_pixel_47_std', 'pressure_mat_pixel_48_mean', 'pressure_mat_pixel_48_std', 'pressure_mat_pixel_49_mean', 'pressure_mat_pixel_49_std', 'pressure_mat_pixel_50_mean', 'pressure_mat_pixel_50_std', 'pressure_mat_pixel_51_mean', 'pressure_mat_pixel_51_std', 'pressure_mat_pixel_52_mean', 'pressure_mat_pixel_52_std', 'pressure_mat_pixel_53_mean', 'pressure_mat_pixel_53_std', 'pressure_mat_pixel_54_mean', 'pressure_mat_pixel_54_std', 'pressure_mat_pixel_55_mean', 'pressure_mat_pixel_55_std', 'pressure_mat_pixel_56_mean', 'pressure_mat_pixel_56_std', 'pressure_mat_pixel_57_mean', 'pressure_mat_pixel_57_std', 'pressure_mat_pixel_58_mean', 'pressure_mat_pixel_58_std', 'pressure_mat_pixel_59_mean', 'pressure_mat_pixel_59_std', 'pressure_mat_pixel_60_mean', 'pressure_mat_pixel_60_std', 'pressure_mat_pixel_61_mean', 'pressure_mat_pixel_61_std', 'pressure_mat_pixel_62_mean', 'pressure_mat_pixel_62_std', 'pressure_mat_pixel_63_mean', 'pressure_mat_pixel_63_std', 'pressure_mat_pixel_64_mean', 'pressure_mat_pixel_64_std', 'pressure_mat_pixel_65_mean', 'pressure_mat_pixel_65_std', 'pressure_mat_pixel_66_mean', 'pressure_mat_pixel_66_std', 'pressure_mat_pixel_67_mean', 'pressure_mat_pixel_67_std', 'pressure_mat_pixel_68_mean', 'pressure_mat_pixel_68_std', 'pressure_mat_pixel_69_mean', 'pressure_mat_pixel_69_std', 'pressure_mat_pixel_70_mean', 'pressure_mat_pixel_70_std', 'pressure_mat_pixel_71_mean', 'pressure_mat_pixel_71_std', 'pressure_mat_pixel_72_mean', 'pressure_mat_pixel_72_std', 'pressure_mat_pixel_73_mean', 'pressure_mat_pixel_73_std', 'pressure_mat_pixel_74_mean', 'pressure_mat_pixel_74_std', 'pressure_mat_pixel_75_mean', 'pressure_mat_pixel_75_std', 'pressure_mat_pixel_76_mean', 'pressure_mat_pixel_76_std', 'pressure_mat_pixel_77_mean', 'pressure_mat_pixel_77_std', 'pressure_mat_pixel_78_mean', 'pressure_mat_pixel_78_std', 'pressure_mat_pixel_79_mean', 'pressure_mat_pixel_79_std', 'pressure_mat_pixel_80_mean', 'pressure_mat_pixel_80_std', 'pressure_mat_pixel_81_mean', 'pressure_mat_pixel_81_std', 'pressure_mat_pixel_82_mean', 'pressure_mat_pixel_82_std', 'pressure_mat_pixel_83_mean', 'pressure_mat_pixel_83_std', 'pressure_mat_pixel_84_mean', 'pressure_mat_pixel_84_std', 'pressure_mat_pixel_85_mean', 'pressure_mat_pixel_85_std', 'pressure_mat_pixel_86_mean', 'pressure_mat_pixel_86_std', 'pressure_mat_pixel_87_mean', 'pressure_mat_pixel_87_std', 'pressure_mat_pixel_88_mean', 'pressure_mat_pixel_88_std', 'pressure_mat_pixel_89_mean', 'pressure_mat_pixel_89_std', 'pressure_mat_pixel_90_mean', 'pressure_mat_pixel_90_std', 'pressure_mat_pixel_91_mean', 'pressure_mat_pixel_91_std', 'pressure_mat_pixel_92_mean', 'pressure_mat_pixel_92_std', 'pressure_mat_pixel_93_mean', 'pressure_mat_pixel_93_std', 'pressure_mat_pixel_94_mean', 'pressure_mat_pixel_94_std', 'pressure_mat_pixel_95_mean', 'pressure_mat_pixel_95_std', 'pressure_mat_pixel_96_mean', 'pressure_mat_pixel_96_std', 'pressure_mat_pixel_97_mean', 'pressure_mat_pixel_97_std', 'pressure_mat_pixel_98_mean', 'pressure_mat_pixel_98_std', 'pressure_mat_pixel_99_mean', 'pressure_mat_pixel_99_std', 'pressure_mat_pixel_100_mean', 'pressure_mat_pixel_100_std', 'pressure_mat_pixel_101_mean', 'pressure_mat_pixel_101_std', 'pressure_mat_pixel_102_mean', 'pressure_mat_pixel_102_std', 'pressure_mat_pixel_103_mean', 'pressure_mat_pixel_103_std', 'pressure_mat_pixel_104_mean', 'pressure_mat_pixel_104_std', 'pressure_mat_pixel_105_mean', 'pressure_mat_pixel_105_std', 'pressure_mat_pixel_106_mean', 'pressure_mat_pixel_106_std', 'pressure_mat_pixel_107_mean', 'pressure_mat_pixel_107_std', 'pressure_mat_pixel_108_mean', 'pressure_mat_pixel_108_std', 'pressure_mat_pixel_109_mean', 'pressure_mat_pixel_109_std', 'pressure_mat_pixel_110_mean', 'pressure_mat_pixel_110_std', 'pressure_mat_pixel_111_mean', 'pressure_mat_pixel_111_std', 'pressure_mat_pixel_112_mean', 'pressure_mat_pixel_112_std', 'pressure_mat_pixel_113_mean', 'pressure_mat_pixel_113_std', 'pressure_mat_pixel_114_mean', 'pressure_mat_pixel_114_std', 'pressure_mat_pixel_115_mean', 'pressure_mat_pixel_115_std', 'pressure_mat_pixel_116_mean', 'pressure_mat_pixel_116_std', 'pressure_mat_pixel_117_mean', 'pressure_mat_pixel_117_std', 'pressure_mat_pixel_118_mean', 'pressure_mat_pixel_118_std', 'pressure_mat_pixel_119_mean', 'pressure_mat_pixel_119_std', 'pressure_mat_pixel_120_mean', 'pressure_mat_pixel_120_std', 'pressure_mat_pixel_121_mean', 'pressure_mat_pixel_121_std', 'pressure_mat_pixel_122_mean', 'pressure_mat_pixel_122_std', 'pressure_mat_pixel_123_mean', 'pressure_mat_pixel_123_std', 'pressure_mat_pixel_124_mean', 'pressure_mat_pixel_124_std', 'pressure_mat_pixel_125_mean', 'pressure_mat_pixel_125_std', 'pressure_mat_pixel_126_mean', 'pressure_mat_pixel_126_std', 'pressure_mat_pixel_127_mean', 'pressure_mat_pixel_127_std', 'pressure_mat_pixel_128_mean', 'pressure_mat_pixel_128_std', 'pressure_mat_pixel_129_mean', 'pressure_mat_pixel_129_std', 'pressure_mat_pixel_130_mean', 'pressure_mat_pixel_130_std', 'pressure_mat_pixel_131_mean', 'pressure_mat_pixel_131_std', 'pressure_mat_pixel_132_mean', 'pressure_mat_pixel_132_std', 'pressure_mat_pixel_133_mean', 'pressure_mat_pixel_133_std', 'pressure_mat_pixel_134_mean', 'pressure_mat_pixel_134_std', 'pressure_mat_pixel_135_mean', 'pressure_mat_pixel_135_std', 'pressure_mat_pixel_136_mean', 'pressure_mat_pixel_136_std', 'pressure_mat_pixel_137_mean', 'pressure_mat_pixel_137_std', 'pressure_mat_pixel_138_mean', 'pressure_mat_pixel_138_std', 'pressure_mat_pixel_139_mean', 'pressure_mat_pixel_139_std', 'pressure_mat_pixel_140_mean', 'pressure_mat_pixel_140_std', 'pressure_mat_pixel_141_mean', 'pressure_mat_pixel_141_std', 'pressure_mat_pixel_142_mean', 'pressure_mat_pixel_142_std', 'pressure_mat_pixel_143_mean', 'pressure_mat_pixel_143_std', 'pressure_mat_pixel_144_mean', 'pressure_mat_pixel_144_std', 'pressure_mat_pixel_145_mean', 'pressure_mat_pixel_145_std', 'pressure_mat_pixel_146_mean', 'pressure_mat_pixel_146_std', 'pressure_mat_pixel_147_mean', 'pressure_mat_pixel_147_std', 'pressure_mat_pixel_148_mean', 'pressure_mat_pixel_148_std', 'pressure_mat_pixel_149_mean', 'pressure_mat_pixel_149_std', 'pressure_mat_pixel_150_mean', 'pressure_mat_pixel_150_std', 'pressure_mat_pixel_151_mean', 'pressure_mat_pixel_151_std', 'pressure_mat_pixel_152_mean', 'pressure_mat_pixel_152_std', 'pressure_mat_pixel_153_mean', 'pressure_mat_pixel_153_std', 'pressure_mat_pixel_154_mean', 'pressure_mat_pixel_154_std', 'pressure_mat_pixel_155_mean', 'pressure_mat_pixel_155_std', 'pressure_mat_pixel_156_mean', 'pressure_mat_pixel_156_std', 'pressure_mat_pixel_157_mean', 'pressure_mat_pixel_157_std', 'pressure_mat_pixel_158_mean', 'pressure_mat_pixel_158_std', 'pressure_mat_pixel_159_mean', 'pressure_mat_pixel_159_std', 'pressure_mat_pixel_160_mean', 'pressure_mat_pixel_160_std', 'pressure_mat_pixel_161_mean', 'pressure_mat_pixel_161_std', 'pressure_mat_pixel_162_mean', 'pressure_mat_pixel_162_std', 'pressure_mat_pixel_163_mean', 'pressure_mat_pixel_163_std', 'pressure_mat_pixel_164_mean', 'pressure_mat_pixel_164_std', 'pressure_mat_pixel_165_mean', 'pressure_mat_pixel_165_std', 'pressure_mat_pixel_166_mean', 'pressure_mat_pixel_166_std', 'pressure_mat_pixel_167_mean', 'pressure_mat_pixel_167_std', 'pressure_mat_pixel_168_mean', 'pressure_mat_pixel_168_std', 'pressure_mat_pixel_169_mean', 'pressure_mat_pixel_169_std', 'pressure_mat_pixel_170_mean', 'pressure_mat_pixel_170_std', 'pressure_mat_pixel_171_mean', 'pressure_mat_pixel_171_std', 'pressure_mat_pixel_172_mean', 'pressure_mat_pixel_172_std', 'pressure_mat_pixel_173_mean', 'pressure_mat_pixel_173_std', 'pressure_mat_pixel_174_mean', 'pressure_mat_pixel_174_std', 'pressure_mat_pixel_175_mean', 'pressure_mat_pixel_175_std', 'pressure_mat_pixel_176_mean', 'pressure_mat_pixel_176_std', 'pressure_mat_pixel_177_mean', 'pressure_mat_pixel_177_std', 'pressure_mat_pixel_178_mean', 'pressure_mat_pixel_178_std', 'pressure_mat_pixel_179_mean', 'pressure_mat_pixel_179_std', 'pressure_mat_pixel_180_mean', 'pressure_mat_pixel_180_std', 'pressure_mat_pixel_181_mean', 'pressure_mat_pixel_181_std', 'pressure_mat_pixel_182_mean', 'pressure_mat_pixel_182_std', 'pressure_mat_pixel_183_mean', 'pressure_mat_pixel_183_std', 'pressure_mat_pixel_184_mean', 'pressure_mat_pixel_184_std', 'pressure_mat_pixel_185_mean', 'pressure_mat_pixel_185_std', 'pressure_mat_pixel_186_mean', 'pressure_mat_pixel_186_std', 'pressure_mat_pixel_187_mean', 'pressure_mat_pixel_187_std', 'pressure_mat_pixel_188_mean', 'pressure_mat_pixel_188_std', 'pressure_mat_pixel_189_mean', 'pressure_mat_pixel_189_std', 'pressure_mat_pixel_190_mean', 'pressure_mat_pixel_190_std', 'pressure_mat_pixel_191_mean', 'pressure_mat_pixel_191_std', 'pressure_mat_pixel_192_mean', 'pressure_mat_pixel_192_std', 'pressure_mat_pixel_193_mean', 'pressure_mat_pixel_193_std', 'pressure_mat_pixel_194_mean', 'pressure_mat_pixel_194_std', 'pressure_mat_pixel_195_mean', 'pressure_mat_pixel_195_std', 'pressure_mat_pixel_196_mean', 'pressure_mat_pixel_196_std', 'pressure_mat_pixel_197_mean', 'pressure_mat_pixel_197_std', 'pressure_mat_pixel_198_mean', 'pressure_mat_pixel_198_std', 'pressure_mat_pixel_199_mean', 'pressure_mat_pixel_199_std', 'pressure_mat_pixel_200_mean', 'pressure_mat_pixel_200_std', 'pressure_mat_pixel_201_mean', 'pressure_mat_pixel_201_std', 'pressure_mat_pixel_202_mean', 'pressure_mat_pixel_202_std', 'pressure_mat_pixel_203_mean', 'pressure_mat_pixel_203_std', 'pressure_mat_pixel_204_mean', 'pressure_mat_pixel_204_std', 'pressure_mat_pixel_205_mean', 'pressure_mat_pixel_205_std', 'pressure_mat_pixel_206_mean', 'pressure_mat_pixel_206_std', 'pressure_mat_pixel_207_mean', 'pressure_mat_pixel_207_std', 'pressure_mat_pixel_208_mean', 'pressure_mat_pixel_208_std', 'pressure_mat_pixel_209_mean', 'pressure_mat_pixel_209_std', 'pressure_mat_pixel_210_mean', 'pressure_mat_pixel_210_std', 'pressure_mat_pixel_211_mean', 'pressure_mat_pixel_211_std', 'pressure_mat_pixel_212_mean', 'pressure_mat_pixel_212_std', 'pressure_mat_pixel_213_mean', 'pressure_mat_pixel_213_std', 'pressure_mat_pixel_214_mean', 'pressure_mat_pixel_214_std', 'pressure_mat_pixel_215_mean', 'pressure_mat_pixel_215_std', 'pressure_mat_pixel_216_mean', 'pressure_mat_pixel_216_std', 'pressure_mat_pixel_217_mean', 'pressure_mat_pixel_217_std', 'pressure_mat_pixel_218_mean', 'pressure_mat_pixel_218_std', 'pressure_mat_pixel_219_mean', 'pressure_mat_pixel_219_std', 'pressure_mat_pixel_220_mean', 'pressure_mat_pixel_220_std', 'pressure_mat_pixel_221_mean', 'pressure_mat_pixel_221_std', 'pressure_mat_pixel_222_mean', 'pressure_mat_pixel_222_std', 'pressure_mat_pixel_223_mean', 'pressure_mat_pixel_223_std', 'pressure_mat_pixel_224_mean', 'pressure_mat_pixel_224_std', 'pressure_mat_pixel_225_mean', 'pressure_mat_pixel_225_std', 'pressure_mat_pixel_226_mean', 'pressure_mat_pixel_226_std', 'pressure_mat_pixel_227_mean', 'pressure_mat_pixel_227_std', 'pressure_mat_pixel_228_mean', 'pressure_mat_pixel_228_std', 'pressure_mat_pixel_229_mean', 'pressure_mat_pixel_229_std', 'pressure_mat_pixel_230_mean', 'pressure_mat_pixel_230_std', 'pressure_mat_pixel_231_mean', 'pressure_mat_pixel_231_std', 'pressure_mat_pixel_232_mean', 'pressure_mat_pixel_232_std', 'pressure_mat_pixel_233_mean', 'pressure_mat_pixel_233_std', 'pressure_mat_pixel_234_mean', 'pressure_mat_pixel_234_std', 'pressure_mat_pixel_235_mean', 'pressure_mat_pixel_235_std', 'pressure_mat_pixel_236_mean', 'pressure_mat_pixel_236_std', 'pressure_mat_pixel_237_mean', 'pressure_mat_pixel_237_std', 'pressure_mat_pixel_238_mean', 'pressure_mat_pixel_238_std', 'pressure_mat_pixel_239_mean', 'pressure_mat_pixel_239_std', 'pressure_mat_pixel_240_mean', 'pressure_mat_pixel_240_std', 'pressure_mat_pixel_241_mean', 'pressure_mat_pixel_241_std', 'pressure_mat_pixel_242_mean', 'pressure_mat_pixel_242_std', 'pressure_mat_pixel_243_mean', 'pressure_mat_pixel_243_std', 'pressure_mat_pixel_244_mean', 'pressure_mat_pixel_244_std', 'pressure_mat_pixel_245_mean', 'pressure_mat_pixel_245_std', 'pressure_mat_pixel_246_mean', 'pressure_mat_pixel_246_std', 'pressure_mat_pixel_247_mean', 'pressure_mat_pixel_247_std', 'pressure_mat_pixel_248_mean', 'pressure_mat_pixel_248_std', 'pressure_mat_pixel_249_mean', 'pressure_mat_pixel_249_std', 'pressure_mat_pixel_250_mean', 'pressure_mat_pixel_250_std', 'pressure_mat_pixel_251_mean', 'pressure_mat_pixel_251_std', 'pressure_mat_pixel_252_mean', 'pressure_mat_pixel_252_std', 'pressure_mat_pixel_253_mean', 'pressure_mat_pixel_253_std', 'pressure_mat_pixel_254_mean', 'pressure_mat_pixel_254_std', 'pressure_mat_pixel_255_mean', 'pressure_mat_pixel_255_std', 'pressure_mat_pixel_256_mean', 'pressure_mat_pixel_256_std', 'pressure_mat_pixel_257_mean', 'pressure_mat_pixel_257_std', 'pressure_mat_pixel_258_mean', 'pressure_mat_pixel_258_std', 'pressure_mat_pixel_259_mean', 'pressure_mat_pixel_259_std', 'pressure_mat_pixel_260_mean', 'pressure_mat_pixel_260_std', 'pressure_mat_pixel_261_mean', 'pressure_mat_pixel_261_std', 'pressure_mat_pixel_262_mean', 'pressure_mat_pixel_262_std', 'pressure_mat_pixel_263_mean', 'pressure_mat_pixel_263_std', 'pressure_mat_pixel_264_mean', 'pressure_mat_pixel_264_std', 'pressure_mat_pixel_265_mean', 'pressure_mat_pixel_265_std', 'pressure_mat_pixel_266_mean', 'pressure_mat_pixel_266_std', 'pressure_mat_pixel_267_mean', 'pressure_mat_pixel_267_std', 'pressure_mat_pixel_268_mean', 'pressure_mat_pixel_268_std', 'pressure_mat_pixel_269_mean', 'pressure_mat_pixel_269_std', 'pressure_mat_pixel_270_mean', 'pressure_mat_pixel_270_std', 'pressure_mat_pixel_271_mean', 'pressure_mat_pixel_271_std', 'pressure_mat_pixel_272_mean', 'pressure_mat_pixel_272_std', 'pressure_mat_pixel_273_mean', 'pressure_mat_pixel_273_std', 'pressure_mat_pixel_274_mean', 'pressure_mat_pixel_274_std', 'pressure_mat_pixel_275_mean', 'pressure_mat_pixel_275_std', 'pressure_mat_pixel_276_mean', 'pressure_mat_pixel_276_std', 'pressure_mat_pixel_277_mean', 'pressure_mat_pixel_277_std', 'pressure_mat_pixel_278_mean', 'pressure_mat_pixel_278_std', 'pressure_mat_pixel_279_mean', 'pressure_mat_pixel_279_std', 'pressure_mat_pixel_280_mean', 'pressure_mat_pixel_280_std', 'pressure_mat_pixel_281_mean', 'pressure_mat_pixel_281_std', 'pressure_mat_pixel_282_mean', 'pressure_mat_pixel_282_std', 'pressure_mat_pixel_283_mean', 'pressure_mat_pixel_283_std', 'pressure_mat_pixel_284_mean', 'pressure_mat_pixel_284_std', 'pressure_mat_pixel_285_mean', 'pressure_mat_pixel_285_std', 'pressure_mat_pixel_286_mean', 'pressure_mat_pixel_286_std', 'pressure_mat_pixel_287_mean', 'pressure_mat_pixel_287_std', 'pressure_mat_pixel_288_mean', 'pressure_mat_pixel_288_std', 'pressure_mat_pixel_289_mean', 'pressure_mat_pixel_289_std', 'pressure_mat_pixel_290_mean', 'pressure_mat_pixel_290_std', 'pressure_mat_pixel_291_mean', 'pressure_mat_pixel_291_std', 'pressure_mat_pixel_292_mean', 'pressure_mat_pixel_292_std', 'pressure_mat_pixel_293_mean', 'pressure_mat_pixel_293_std', 'pressure_mat_pixel_294_mean', 'pressure_mat_pixel_294_std', 'pressure_mat_pixel_295_mean', 'pressure_mat_pixel_295_std', 'pressure_mat_pixel_296_mean', 'pressure_mat_pixel_296_std', 'pressure_mat_pixel_297_mean', 'pressure_mat_pixel_297_std', 'pressure_mat_pixel_298_mean', 'pressure_mat_pixel_298_std', 'pressure_mat_pixel_299_mean', 'pressure_mat_pixel_299_std', 'pressure_mat_pixel_300_mean', 'pressure_mat_pixel_300_std', 'pressure_mat_pixel_301_mean', 'pressure_mat_pixel_301_std', 'pressure_mat_pixel_302_mean', 'pressure_mat_pixel_302_std', 'pressure_mat_pixel_303_mean', 'pressure_mat_pixel_303_std', 'pressure_mat_pixel_304_mean', 'pressure_mat_pixel_304_std', 'pressure_mat_pixel_305_mean', 'pressure_mat_pixel_305_std', 'pressure_mat_pixel_306_mean', 'pressure_mat_pixel_306_std', 'pressure_mat_pixel_307_mean', 'pressure_mat_pixel_307_std', 'pressure_mat_pixel_308_mean', 'pressure_mat_pixel_308_std', 'pressure_mat_pixel_309_mean', 'pressure_mat_pixel_309_std', 'pressure_mat_pixel_310_mean', 'pressure_mat_pixel_310_std', 'pressure_mat_pixel_311_mean', 'pressure_mat_pixel_311_std', 'pressure_mat_pixel_312_mean', 'pressure_mat_pixel_312_std', 'pressure_mat_pixel_313_mean', 'pressure_mat_pixel_313_std', 'pressure_mat_pixel_314_mean', 'pressure_mat_pixel_314_std', 'pressure_mat_pixel_315_mean', 'pressure_mat_pixel_315_std', 'pressure_mat_pixel_316_mean', 'pressure_mat_pixel_316_std', 'pressure_mat_pixel_317_mean', 'pressure_mat_pixel_317_std', 'pressure_mat_pixel_318_mean', 'pressure_mat_pixel_318_std', 'pressure_mat_pixel_319_mean', 'pressure_mat_pixel_319_std', 'pressure_mat_pixel_320_mean', 'pressure_mat_pixel_320_std', 'pressure_mat_pixel_321_mean', 'pressure_mat_pixel_321_std', 'pressure_mat_pixel_322_mean', 'pressure_mat_pixel_322_std', 'pressure_mat_pixel_323_mean', 'pressure_mat_pixel_323_std', 'pressure_mat_pixel_324_mean', 'pressure_mat_pixel_324_std', 'pressure_mat_pixel_325_mean', 'pressure_mat_pixel_325_std', 'pressure_mat_pixel_326_mean', 'pressure_mat_pixel_326_std', 'pressure_mat_pixel_327_mean', 'pressure_mat_pixel_327_std', 'pressure_mat_pixel_328_mean', 'pressure_mat_pixel_328_std', 'pressure_mat_pixel_329_mean', 'pressure_mat_pixel_329_std', 'pressure_mat_pixel_330_mean', 'pressure_mat_pixel_330_std', 'pressure_mat_pixel_331_mean', 'pressure_mat_pixel_331_std', 'pressure_mat_pixel_332_mean', 'pressure_mat_pixel_332_std', 'pressure_mat_pixel_333_mean', 'pressure_mat_pixel_333_std', 'pressure_mat_pixel_334_mean', 'pressure_mat_pixel_334_std', 'pressure_mat_pixel_335_mean', 'pressure_mat_pixel_335_std', 'pressure_mat_pixel_336_mean', 'pressure_mat_pixel_336_std', 'pressure_mat_pixel_337_mean', 'pressure_mat_pixel_337_std', 'pressure_mat_pixel_338_mean', 'pressure_mat_pixel_338_std', 'pressure_mat_pixel_339_mean', 'pressure_mat_pixel_339_std', 'pressure_mat_pixel_340_mean', 'pressure_mat_pixel_340_std', 'pressure_mat_pixel_341_mean', 'pressure_mat_pixel_341_std', 'pressure_mat_pixel_342_mean', 'pressure_mat_pixel_342_std', 'pressure_mat_pixel_343_mean', 'pressure_mat_pixel_343_std', 'pressure_mat_pixel_344_mean', 'pressure_mat_pixel_344_std', 'pressure_mat_pixel_345_mean', 'pressure_mat_pixel_345_std', 'pressure_mat_pixel_346_mean', 'pressure_mat_pixel_346_std', 'pressure_mat_pixel_347_mean', 'pressure_mat_pixel_347_std', 'pressure_mat_pixel_348_mean', 'pressure_mat_pixel_348_std', 'pressure_mat_pixel_349_mean', 'pressure_mat_pixel_349_std', 'pressure_mat_pixel_350_mean', 'pressure_mat_pixel_350_std', 'pressure_mat_pixel_351_mean', 'pressure_mat_pixel_351_std', 'pressure_mat_pixel_352_mean', 'pressure_mat_pixel_352_std', 'pressure_mat_pixel_353_mean', 'pressure_mat_pixel_353_std', 'pressure_mat_pixel_354_mean', 'pressure_mat_pixel_354_std', 'pressure_mat_pixel_355_mean', 'pressure_mat_pixel_355_std', 'pressure_mat_pixel_356_mean', 'pressure_mat_pixel_356_std', 'pressure_mat_pixel_357_mean', 'pressure_mat_pixel_357_std', 'pressure_mat_pixel_358_mean', 'pressure_mat_pixel_358_std', 'pressure_mat_pixel_359_mean', 'pressure_mat_pixel_359_std', 'pressure_mat_pixel_360_mean', 'pressure_mat_pixel_360_std', 'pressure_mat_pixel_361_mean', 'pressure_mat_pixel_361_std', 'pressure_mat_pixel_362_mean', 'pressure_mat_pixel_362_std', 'pressure_mat_pixel_363_mean', 'pressure_mat_pixel_363_std', 'pressure_mat_pixel_364_mean', 'pressure_mat_pixel_364_std', 'pressure_mat_pixel_365_mean', 'pressure_mat_pixel_365_std', 'pressure_mat_pixel_366_mean', 'pressure_mat_pixel_366_std', 'pressure_mat_pixel_367_mean', 'pressure_mat_pixel_367_std', 'pressure_mat_pixel_368_mean', 'pressure_mat_pixel_368_std', 'pressure_mat_pixel_369_mean', 'pressure_mat_pixel_369_std', 'pressure_mat_pixel_370_mean', 'pressure_mat_pixel_370_std', 'pressure_mat_pixel_371_mean', 'pressure_mat_pixel_371_std', 'pressure_mat_pixel_372_mean', 'pressure_mat_pixel_372_std', 'pressure_mat_pixel_373_mean', 'pressure_mat_pixel_373_std', 'pressure_mat_pixel_374_mean', 'pressure_mat_pixel_374_std', 'pressure_mat_pixel_375_mean', 'pressure_mat_pixel_375_std', 'pressure_mat_pixel_376_mean', 'pressure_mat_pixel_376_std', 'pressure_mat_pixel_377_mean', 'pressure_mat_pixel_377_std', 'pressure_mat_pixel_378_mean', 'pressure_mat_pixel_378_std', 'pressure_mat_pixel_379_mean', 'pressure_mat_pixel_379_std', 'pressure_mat_pixel_380_mean', 'pressure_mat_pixel_380_std', 'pressure_mat_pixel_381_mean', 'pressure_mat_pixel_381_std', 'pressure_mat_pixel_382_mean', 'pressure_mat_pixel_382_std', 'pressure_mat_pixel_383_mean', 'pressure_mat_pixel_383_std', 'pressure_mat_pixel_384_mean', 'pressure_mat_pixel_384_std', 'pressure_mat_pixel_385_mean', 'pressure_mat_pixel_385_std', 'pressure_mat_pixel_386_mean', 'pressure_mat_pixel_386_std', 'pressure_mat_pixel_387_mean', 'pressure_mat_pixel_387_std', 'pressure_mat_pixel_388_mean', 'pressure_mat_pixel_388_std', 'pressure_mat_pixel_389_mean', 'pressure_mat_pixel_389_std', 'pressure_mat_pixel_390_mean', 'pressure_mat_pixel_390_std', 'pressure_mat_pixel_391_mean', 'pressure_mat_pixel_391_std', 'pressure_mat_pixel_392_mean', 'pressure_mat_pixel_392_std', 'pressure_mat_pixel_393_mean', 'pressure_mat_pixel_393_std', 'pressure_mat_pixel_394_mean', 'pressure_mat_pixel_394_std', 'pressure_mat_pixel_395_mean', 'pressure_mat_pixel_395_std', 'pressure_mat_pixel_396_mean', 'pressure_mat_pixel_396_std', 'pressure_mat_pixel_397_mean', 'pressure_mat_pixel_397_std', 'pressure_mat_pixel_398_mean', 'pressure_mat_pixel_398_std', 'pressure_mat_pixel_399_mean', 'pressure_mat_pixel_399_std', 'pressure_mat_pixel_400_mean', 'pressure_mat_pixel_400_std', 'pressure_mat_pixel_401_mean', 'pressure_mat_pixel_401_std', 'pressure_mat_pixel_402_mean', 'pressure_mat_pixel_402_std', 'pressure_mat_pixel_403_mean', 'pressure_mat_pixel_403_std', 'pressure_mat_pixel_404_mean', 'pressure_mat_pixel_404_std', 'pressure_mat_pixel_405_mean', 'pressure_mat_pixel_405_std', 'pressure_mat_pixel_406_mean', 'pressure_mat_pixel_406_std', 'pressure_mat_pixel_407_mean', 'pressure_mat_pixel_407_std', 'pressure_mat_pixel_408_mean', 'pressure_mat_pixel_408_std', 'pressure_mat_pixel_409_mean', 'pressure_mat_pixel_409_std', 'pressure_mat_pixel_410_mean', 'pressure_mat_pixel_410_std', 'pressure_mat_pixel_411_mean', 'pressure_mat_pixel_411_std', 'pressure_mat_pixel_412_mean', 'pressure_mat_pixel_412_std', 'pressure_mat_pixel_413_mean', 'pressure_mat_pixel_413_std', 'pressure_mat_pixel_414_mean', 'pressure_mat_pixel_414_std', 'pressure_mat_pixel_415_mean', 'pressure_mat_pixel_415_std', 'pressure_mat_pixel_416_mean', 'pressure_mat_pixel_416_std', 'pressure_mat_pixel_417_mean', 'pressure_mat_pixel_417_std', 'pressure_mat_pixel_418_mean', 'pressure_mat_pixel_418_std', 'pressure_mat_pixel_419_mean', 'pressure_mat_pixel_419_std', 'pressure_mat_pixel_420_mean', 'pressure_mat_pixel_420_std', 'pressure_mat_pixel_421_mean', 'pressure_mat_pixel_421_std', 'pressure_mat_pixel_422_mean', 'pressure_mat_pixel_422_std', 'pressure_mat_pixel_423_mean', 'pressure_mat_pixel_423_std', 'pressure_mat_pixel_424_mean', 'pressure_mat_pixel_424_std', 'pressure_mat_pixel_425_mean', 'pressure_mat_pixel_425_std', 'pressure_mat_pixel_426_mean', 'pressure_mat_pixel_426_std', 'pressure_mat_pixel_427_mean', 'pressure_mat_pixel_427_std', 'pressure_mat_pixel_428_mean', 'pressure_mat_pixel_428_std', 'pressure_mat_pixel_429_mean', 'pressure_mat_pixel_429_std', 'pressure_mat_pixel_430_mean', 'pressure_mat_pixel_430_std', 'pressure_mat_pixel_431_mean', 'pressure_mat_pixel_431_std', 'pressure_mat_pixel_432_mean', 'pressure_mat_pixel_432_std', 'pressure_mat_pixel_433_mean', 'pressure_mat_pixel_433_std', 'pressure_mat_pixel_434_mean', 'pressure_mat_pixel_434_std', 'pressure_mat_pixel_435_mean', 'pressure_mat_pixel_435_std', 'pressure_mat_pixel_436_mean', 'pressure_mat_pixel_436_std', 'pressure_mat_pixel_437_mean', 'pressure_mat_pixel_437_std', 'pressure_mat_pixel_438_mean', 'pressure_mat_pixel_438_std', 'pressure_mat_pixel_439_mean', 'pressure_mat_pixel_439_std', 'pressure_mat_pixel_440_mean', 'pressure_mat_pixel_440_std', 'pressure_mat_pixel_441_mean', 'pressure_mat_pixel_441_std', 'pressure_mat_pixel_442_mean', 'pressure_mat_pixel_442_std', 'pressure_mat_pixel_443_mean', 'pressure_mat_pixel_443_std', 'pressure_mat_pixel_444_mean', 'pressure_mat_pixel_444_std', 'pressure_mat_pixel_445_mean', 'pressure_mat_pixel_445_std', 'pressure_mat_pixel_446_mean', 'pressure_mat_pixel_446_std', 'pressure_mat_pixel_447_mean', 'pressure_mat_pixel_447_std', 'pressure_mat_pixel_448_mean', 'pressure_mat_pixel_448_std', 'pressure_mat_pixel_449_mean', 'pressure_mat_pixel_449_std', 'pressure_mat_pixel_450_mean', 'pressure_mat_pixel_450_std', 'pressure_mat_pixel_451_mean', 'pressure_mat_pixel_451_std', 'pressure_mat_pixel_452_mean', 'pressure_mat_pixel_452_std', 'pressure_mat_pixel_453_mean', 'pressure_mat_pixel_453_std', 'pressure_mat_pixel_454_mean', 'pressure_mat_pixel_454_std', 'pressure_mat_pixel_455_mean', 'pressure_mat_pixel_455_std', 'pressure_mat_pixel_456_mean', 'pressure_mat_pixel_456_std', 'pressure_mat_pixel_457_mean', 'pressure_mat_pixel_457_std', 'pressure_mat_pixel_458_mean', 'pressure_mat_pixel_458_std', 'pressure_mat_pixel_459_mean', 'pressure_mat_pixel_459_std', 'pressure_mat_pixel_460_mean', 'pressure_mat_pixel_460_std', 'pressure_mat_pixel_461_mean', 'pressure_mat_pixel_461_std', 'pressure_mat_pixel_462_mean', 'pressure_mat_pixel_462_std', 'pressure_mat_pixel_463_mean', 'pressure_mat_pixel_463_std', 'pressure_mat_pixel_464_mean', 'pressure_mat_pixel_464_std', 'pressure_mat_pixel_465_mean', 'pressure_mat_pixel_465_std', 'pressure_mat_pixel_466_mean', 'pressure_mat_pixel_466_std', 'pressure_mat_pixel_467_mean', 'pressure_mat_pixel_467_std', 'pressure_mat_pixel_468_mean', 'pressure_mat_pixel_468_std', 'pressure_mat_pixel_469_mean', 'pressure_mat_pixel_469_std', 'pressure_mat_pixel_470_mean', 'pressure_mat_pixel_470_std', 'pressure_mat_pixel_471_mean', 'pressure_mat_pixel_471_std', 'pressure_mat_pixel_472_mean', 'pressure_mat_pixel_472_std', 'pressure_mat_pixel_473_mean', 'pressure_mat_pixel_473_std', 'pressure_mat_pixel_474_mean', 'pressure_mat_pixel_474_std', 'pressure_mat_pixel_475_mean', 'pressure_mat_pixel_475_std', 'pressure_mat_pixel_476_mean', 'pressure_mat_pixel_476_std', 'pressure_mat_pixel_477_mean', 'pressure_mat_pixel_477_std', 'pressure_mat_pixel_478_mean', 'pressure_mat_pixel_478_std', 'pressure_mat_pixel_479_mean', 'pressure_mat_pixel_479_std', 'pressure_mat_pixel_480_mean', 'pressure_mat_pixel_480_std', 'pressure_mat_pixel_481_mean', 'pressure_mat_pixel_481_std', 'pressure_mat_pixel_482_mean', 'pressure_mat_pixel_482_std', 'pressure_mat_pixel_483_mean', 'pressure_mat_pixel_483_std', 'pressure_mat_pixel_484_mean', 'pressure_mat_pixel_484_std', 'pressure_mat_pixel_485_mean', 'pressure_mat_pixel_485_std', 'pressure_mat_pixel_486_mean', 'pressure_mat_pixel_486_std', 'pressure_mat_pixel_487_mean', 'pressure_mat_pixel_487_std', 'pressure_mat_pixel_488_mean', 'pressure_mat_pixel_488_std', 'pressure_mat_pixel_489_mean', 'pressure_mat_pixel_489_std', 'pressure_mat_pixel_490_mean', 'pressure_mat_pixel_490_std', 'pressure_mat_pixel_491_mean', 'pressure_mat_pixel_491_std', 'pressure_mat_pixel_492_mean', 'pressure_mat_pixel_492_std', 'pressure_mat_pixel_493_mean', 'pressure_mat_pixel_493_std', 'pressure_mat_pixel_494_mean', 'pressure_mat_pixel_494_std', 'pressure_mat_pixel_495_mean', 'pressure_mat_pixel_495_std', 'pressure_mat_pixel_496_mean', 'pressure_mat_pixel_496_std', 'pressure_mat_pixel_497_mean', 'pressure_mat_pixel_497_std', 'pressure_mat_pixel_498_mean', 'pressure_mat_pixel_498_std', 'pressure_mat_pixel_499_mean', 'pressure_mat_pixel_499_std', 'pressure_mat_pixel_500_mean', 'pressure_mat_pixel_500_std', 'pressure_mat_pixel_501_mean', 'pressure_mat_pixel_501_std', 'pressure_mat_pixel_502_mean', 'pressure_mat_pixel_502_std', 'pressure_mat_pixel_503_mean', 'pressure_mat_pixel_503_std', 'pressure_mat_pixel_504_mean', 'pressure_mat_pixel_504_std', 'pressure_mat_pixel_505_mean', 'pressure_mat_pixel_505_std', 'pressure_mat_pixel_506_mean', 'pressure_mat_pixel_506_std', 'pressure_mat_pixel_507_mean', 'pressure_mat_pixel_507_std', 'pressure_mat_pixel_508_mean', 'pressure_mat_pixel_508_std', 'pressure_mat_pixel_509_mean', 'pressure_mat_pixel_509_std', 'pressure_mat_pixel_510_mean', 'pressure_mat_pixel_510_std', 'pressure_mat_pixel_511_mean', 'pressure_mat_pixel_511_std', 'depth_pixel_0_mean', 'depth_pixel_0_std', 'depth_pixel_1_mean', 'depth_pixel_1_std', 'depth_pixel_2_mean', 'depth_pixel_2_std', 'depth_pixel_3_mean', 'depth_pixel_3_std', 'depth_pixel_4_mean', 'depth_pixel_4_std', 'depth_pixel_5_mean', 'depth_pixel_5_std', 'depth_pixel_6_mean', 'depth_pixel_6_std', 'depth_pixel_7_mean', 'depth_pixel_7_std', 'depth_pixel_8_mean', 'depth_pixel_8_std', 'depth_pixel_9_mean', 'depth_pixel_9_std', 'depth_pixel_10_mean', 'depth_pixel_10_std', 'depth_pixel_11_mean', 'depth_pixel_11_std', 'depth_pixel_12_mean', 'depth_pixel_12_std', 'depth_pixel_13_mean', 'depth_pixel_13_std', 'depth_pixel_14_mean', 'depth_pixel_14_std', 'depth_pixel_15_mean', 'depth_pixel_15_std', 'depth_pixel_16_mean', 'depth_pixel_16_std', 'depth_pixel_17_mean', 'depth_pixel_17_std', 'depth_pixel_18_mean', 'depth_pixel_18_std', 'depth_pixel_19_mean', 'depth_pixel_19_std', 'depth_pixel_20_mean', 'depth_pixel_20_std', 'depth_pixel_21_mean', 'depth_pixel_21_std', 'depth_pixel_22_mean', 'depth_pixel_22_std', 'depth_pixel_23_mean', 'depth_pixel_23_std', 'depth_pixel_24_mean', 'depth_pixel_24_std', 'depth_pixel_25_mean', 'depth_pixel_25_std', 'depth_pixel_26_mean', 'depth_pixel_26_std', 'depth_pixel_27_mean', 'depth_pixel_27_std', 'depth_pixel_28_mean', 'depth_pixel_28_std', 'depth_pixel_29_mean', 'depth_pixel_29_std', 'depth_pixel_30_mean', 'depth_pixel_30_std', 'depth_pixel_31_mean', 'depth_pixel_31_std', 'depth_pixel_32_mean', 'depth_pixel_32_std', 'depth_pixel_33_mean', 'depth_pixel_33_std', 'depth_pixel_34_mean', 'depth_pixel_34_std', 'depth_pixel_35_mean', 'depth_pixel_35_std', 'depth_pixel_36_mean', 'depth_pixel_36_std', 'depth_pixel_37_mean', 'depth_pixel_37_std', 'depth_pixel_38_mean', 'depth_pixel_38_std', 'depth_pixel_39_mean', 'depth_pixel_39_std', 'depth_pixel_40_mean', 'depth_pixel_40_std', 'depth_pixel_41_mean', 'depth_pixel_41_std', 'depth_pixel_42_mean', 'depth_pixel_42_std', 'depth_pixel_43_mean', 'depth_pixel_43_std', 'depth_pixel_44_mean', 'depth_pixel_44_std', 'depth_pixel_45_mean', 'depth_pixel_45_std', 'depth_pixel_46_mean', 'depth_pixel_46_std', 'depth_pixel_47_mean', 'depth_pixel_47_std', 'depth_pixel_48_mean', 'depth_pixel_48_std', 'depth_pixel_49_mean', 'depth_pixel_49_std', 'depth_pixel_50_mean', 'depth_pixel_50_std', 'depth_pixel_51_mean', 'depth_pixel_51_std', 'depth_pixel_52_mean', 'depth_pixel_52_std', 'depth_pixel_53_mean', 'depth_pixel_53_std', 'depth_pixel_54_mean', 'depth_pixel_54_std', 'depth_pixel_55_mean', 'depth_pixel_55_std', 'depth_pixel_56_mean', 'depth_pixel_56_std', 'depth_pixel_57_mean', 'depth_pixel_57_std', 'depth_pixel_58_mean', 'depth_pixel_58_std', 'depth_pixel_59_mean', 'depth_pixel_59_std', 'depth_pixel_60_mean', 'depth_pixel_60_std', 'depth_pixel_61_mean', 'depth_pixel_61_std', 'depth_pixel_62_mean', 'depth_pixel_62_std', 'depth_pixel_63_mean', 'depth_pixel_63_std', 'depth_pixel_64_mean', 'depth_pixel_64_std', 'depth_pixel_65_mean', 'depth_pixel_65_std', 'depth_pixel_66_mean', 'depth_pixel_66_std', 'depth_pixel_67_mean', 'depth_pixel_67_std', 'depth_pixel_68_mean', 'depth_pixel_68_std', 'depth_pixel_69_mean', 'depth_pixel_69_std', 'depth_pixel_70_mean', 'depth_pixel_70_std', 'depth_pixel_71_mean', 'depth_pixel_71_std', 'depth_pixel_72_mean', 'depth_pixel_72_std', 'depth_pixel_73_mean', 'depth_pixel_73_std', 'depth_pixel_74_mean', 'depth_pixel_74_std', 'depth_pixel_75_mean', 'depth_pixel_75_std', 'depth_pixel_76_mean', 'depth_pixel_76_std', 'depth_pixel_77_mean', 'depth_pixel_77_std', 'depth_pixel_78_mean', 'depth_pixel_78_std', 'depth_pixel_79_mean', 'depth_pixel_79_std', 'depth_pixel_80_mean', 'depth_pixel_80_std', 'depth_pixel_81_mean', 'depth_pixel_81_std', 'depth_pixel_82_mean', 'depth_pixel_82_std', 'depth_pixel_83_mean', 'depth_pixel_83_std', 'depth_pixel_84_mean', 'depth_pixel_84_std', 'depth_pixel_85_mean', 'depth_pixel_85_std', 'depth_pixel_86_mean', 'depth_pixel_86_std', 'depth_pixel_87_mean', 'depth_pixel_87_std', 'depth_pixel_88_mean', 'depth_pixel_88_std', 'depth_pixel_89_mean', 'depth_pixel_89_std', 'depth_pixel_90_mean', 'depth_pixel_90_std', 'depth_pixel_91_mean', 'depth_pixel_91_std', 'depth_pixel_92_mean', 'depth_pixel_92_std', 'depth_pixel_93_mean', 'depth_pixel_93_std', 'depth_pixel_94_mean', 'depth_pixel_94_std', 'depth_pixel_95_mean', 'depth_pixel_95_std', 'depth_pixel_96_mean', 'depth_pixel_96_std', 'depth_pixel_97_mean', 'depth_pixel_97_std', 'depth_pixel_98_mean', 'depth_pixel_98_std', 'depth_pixel_99_mean', 'depth_pixel_99_std', 'depth_pixel_100_mean', 'depth_pixel_100_std', 'depth_pixel_101_mean', 'depth_pixel_101_std', 'depth_pixel_102_mean', 'depth_pixel_102_std', 'depth_pixel_103_mean', 'depth_pixel_103_std', 'depth_pixel_104_mean', 'depth_pixel_104_std', 'depth_pixel_105_mean', 'depth_pixel_105_std', 'depth_pixel_106_mean', 'depth_pixel_106_std', 'depth_pixel_107_mean', 'depth_pixel_107_std', 'depth_pixel_108_mean', 'depth_pixel_108_std', 'depth_pixel_109_mean', 'depth_pixel_109_std', 'depth_pixel_110_mean', 'depth_pixel_110_std', 'depth_pixel_111_mean', 'depth_pixel_111_std', 'depth_pixel_112_mean', 'depth_pixel_112_std', 'depth_pixel_113_mean', 'depth_pixel_113_std', 'depth_pixel_114_mean', 'depth_pixel_114_std', 'depth_pixel_115_mean', 'depth_pixel_115_std', 'depth_pixel_116_mean', 'depth_pixel_116_std', 'depth_pixel_117_mean', 'depth_pixel_117_std', 'depth_pixel_118_mean', 'depth_pixel_118_std', 'depth_pixel_119_mean', 'depth_pixel_119_std', 'depth_pixel_120_mean', 'depth_pixel_120_std', 'depth_pixel_121_mean', 'depth_pixel_121_std', 'depth_pixel_122_mean', 'depth_pixel_122_std', 'depth_pixel_123_mean', 'depth_pixel_123_std', 'depth_pixel_124_mean', 'depth_pixel_124_std', 'depth_pixel_125_mean', 'depth_pixel_125_std', 'depth_pixel_126_mean', 'depth_pixel_126_std', 'depth_pixel_127_mean', 'depth_pixel_127_std', 'depth_pixel_128_mean', 'depth_pixel_128_std', 'depth_pixel_129_mean', 'depth_pixel_129_std', 'depth_pixel_130_mean', 'depth_pixel_130_std', 'depth_pixel_131_mean', 'depth_pixel_131_std', 'depth_pixel_132_mean', 'depth_pixel_132_std', 'depth_pixel_133_mean', 'depth_pixel_133_std', 'depth_pixel_134_mean', 'depth_pixel_134_std', 'depth_pixel_135_mean', 'depth_pixel_135_std', 'depth_pixel_136_mean', 'depth_pixel_136_std', 'depth_pixel_137_mean', 'depth_pixel_137_std', 'depth_pixel_138_mean', 'depth_pixel_138_std', 'depth_pixel_139_mean', 'depth_pixel_139_std', 'depth_pixel_140_mean', 'depth_pixel_140_std', 'depth_pixel_141_mean', 'depth_pixel_141_std', 'depth_pixel_142_mean', 'depth_pixel_142_std', 'depth_pixel_143_mean', 'depth_pixel_143_std', 'depth_pixel_144_mean', 'depth_pixel_144_std', 'depth_pixel_145_mean', 'depth_pixel_145_std', 'depth_pixel_146_mean', 'depth_pixel_146_std', 'depth_pixel_147_mean', 'depth_pixel_147_std', 'depth_pixel_148_mean', 'depth_pixel_148_std', 'depth_pixel_149_mean', 'depth_pixel_149_std', 'depth_pixel_150_mean', 'depth_pixel_150_std', 'depth_pixel_151_mean', 'depth_pixel_151_std', 'depth_pixel_152_mean', 'depth_pixel_152_std', 'depth_pixel_153_mean', 'depth_pixel_153_std', 'depth_pixel_154_mean', 'depth_pixel_154_std', 'depth_pixel_155_mean', 'depth_pixel_155_std', 'depth_pixel_156_mean', 'depth_pixel_156_std', 'depth_pixel_157_mean', 'depth_pixel_157_std', 'depth_pixel_158_mean', 'depth_pixel_158_std', 'depth_pixel_159_mean', 'depth_pixel_159_std', 'depth_pixel_160_mean', 'depth_pixel_160_std', 'depth_pixel_161_mean', 'depth_pixel_161_std', 'depth_pixel_162_mean', 'depth_pixel_162_std', 'depth_pixel_163_mean', 'depth_pixel_163_std', 'depth_pixel_164_mean', 'depth_pixel_164_std', 'depth_pixel_165_mean', 'depth_pixel_165_std', 'depth_pixel_166_mean', 'depth_pixel_166_std', 'depth_pixel_167_mean', 'depth_pixel_167_std', 'depth_pixel_168_mean', 'depth_pixel_168_std', 'depth_pixel_169_mean', 'depth_pixel_169_std', 'depth_pixel_170_mean', 'depth_pixel_170_std', 'depth_pixel_171_mean', 'depth_pixel_171_std', 'depth_pixel_172_mean', 'depth_pixel_172_std', 'depth_pixel_173_mean', 'depth_pixel_173_std', 'depth_pixel_174_mean', 'depth_pixel_174_std', 'depth_pixel_175_mean', 'depth_pixel_175_std', 'depth_pixel_176_mean', 'depth_pixel_176_std', 'depth_pixel_177_mean', 'depth_pixel_177_std', 'depth_pixel_178_mean', 'depth_pixel_178_std', 'depth_pixel_179_mean', 'depth_pixel_179_std', 'depth_pixel_180_mean', 'depth_pixel_180_std', 'depth_pixel_181_mean', 'depth_pixel_181_std', 'depth_pixel_182_mean', 'depth_pixel_182_std', 'depth_pixel_183_mean', 'depth_pixel_183_std', 'depth_pixel_184_mean', 'depth_pixel_184_std', 'depth_pixel_185_mean', 'depth_pixel_185_std', 'depth_pixel_186_mean', 'depth_pixel_186_std', 'depth_pixel_187_mean', 'depth_pixel_187_std', 'depth_pixel_188_mean', 'depth_pixel_188_std', 'depth_pixel_189_mean', 'depth_pixel_189_std', 'depth_pixel_190_mean', 'depth_pixel_190_std', 'depth_pixel_191_mean', 'depth_pixel_191_std']\n",
      "\n",
      "Examples of subject IDs :  [17  6 25  7 10]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGzCAYAAAAFROyYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAM5FJREFUeJzt3QtcVWW+//GfAoKCQJiAFpCZpXjJ0lLUslGSzExHp7JjhkrWcdS8TFbMMXW8RHrM6/GS/h20Yx5Hm/E65g1LT+Pdxo5pBy85ainQjAFqI4Lu/+v3vM7e7Y2AbsV4gM/79Vpu91prr/3stfdmfddzWbuKw+FwCAAAgEWqlnUBAAAACiOgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaCgwhg7dqxUqVLlZ3muJ554wkxOn332mXnujz/++Gd5/r59+8o999wjNrtw4YK88sorEhkZafbNsGHDpCKx9T2wtVyAtwgosNKiRYvMQc05BQQESN26dSUhIUFmzpwp58+fL5XnOXPmjAk2Bw4cENvYXLYb8e6775r3ceDAgfKf//mf0qdPn7IuEoByxLesCwCUZNy4cVKvXj3Jz8+XjIwMU1OhZ+JTp06VNWvWSLNmzVzrjho1St5++22vQ8Dvfvc7c8bZvHnzG37cpk2bbvsbV1LZFixYIFevXhWbbd26VVq3bi1jxoyRiqg8vAdAeUZAgdU6d+4sLVu2dN1PTk42B75nnnlGnn32Wfn666+levXqZpmvr6+Zbqcff/xRatSoIdWqVZOy5OfnJ7bLysqS2NhYKU8uXrwogYGBFeY9AMozmnhQ7nTo0EHeeecdOXnypCxZsqTEPiibN2+Wdu3aSWhoqAQFBckDDzwgv/3tb80yrY155JFHzP/79evnak7SZgmlfUyaNGki+/fvl8cff9wEE+djC/dBcbpy5YpZR/td6IFOQ9Tp06c91tEaEe0nUJj7Nq9XtqL6GejB9Te/+Y1ERUWJv7+/ea1TpkyRwj9YrtsZPHiwrFq1yrw+Xbdx48ayYcOGGw4eSUlJEhERYZreHnzwQVm8ePE1/XFOnDghf/7zn11l/9vf/lbidvW9bNGihQmcYWFh0qtXL499l5qaarbz+9///pqmJJ2/fv1617z//d//lV/96ldmO1pGDbla41ZUM+K2bdvk17/+tYSHh8vdd9/tWv7JJ59I+/btpWbNmhIcHGzej6VLl7qWF/UeLFu2zLwG52OaNm0qM2bM8FgnOzvb1AI636f77rtPJk2adMO1MdcrV1H0c9CmTRupVauW2b9axqL6S5X0fXGaNWuW+bzo9+GOO+4w+7bw83/33XfSv39/8xlxfr4Kv283ui1UXtSgoFzS/gz6h1ObWgYMGFDkOocOHTI1LdoMpE1F+ofy2LFj8pe//MUsb9SokZk/evRoefXVV+Wxxx4z8/UPudM//vEPU4ujB8uXXnrJ/MEtycSJE81B76233jIH8unTp0t8fLzpR+Ks6bkRN1I2dxpCNAx9+umnJjxok9DGjRtl5MiR5mAxbdo0j/U///xz+dOf/mQOzHqg0349PXv2lFOnTpmDWHH++c9/mhCl+1FDjja/rVixwhys9cA7dOhQU3btczJ8+HBzwNfQpGrXrl3iftPQ+fzzz5uOtd9//705eGkw/Otf/2oOmBrUtMwjRoyQJ5980hzgDx48aJrB9DU//fTTrve9bdu2ctddd5kmPw2Ky5cvl+7du8sf//hH+eUvf+nx3LoPtGy6rzXkOcOLHmD14Km1dvr8Wg4Ncf/yL/9S5GvQg/uLL74oHTt2NIFDaQ2fft50vzhr4DRc6Hvy2muvSXR0tOzYscM8x9mzZ83npSQ3Uy6lIUk/H71795bLly+bIPXcc8/JunXrpEuXLjf0fXE2a73++usm/OlrunTpkvzP//yP7N692/X8mZmZpmnPGYR132qo0vcoNzfX1Vn6RraFSs4BWCg1NVVP+x179+4tdp2QkBDHQw895Lo/ZswY8xinadOmmfvff/99sdvQ7es6+nyFtW/f3iybN29ekct0cvr000/NunfddZcjNzfXNX/58uVm/owZM1zzYmJiHImJidfdZkll08frdpxWrVpl1p0wYYLHer/61a8cVapUcRw7dsw1T9erVq2ax7wvv/zSzJ81a5ajJNOnTzfrLVmyxDXv8uXLjri4OEdQUJDHa9fydenSxXE9f/vb3xw+Pj6OiRMnesw/ePCgw9fX12P+2bNnHWFhYY4nn3zSkZeXZ97/6OhoR05Ojmudjh07Opo2beq4dOmSa97Vq1cdbdq0cTRo0OCaz1i7du0cBQUFrvnZ2dmOmjVrOlq1auX45z//6VEm3U5x78HQoUMdwcHBHtsqbPz48Y7AwEDHkSNHPOa//fbbZh+cOnWq2MfebLnUjz/+6HFf37MmTZo4OnTo4NX3pVu3bo7GjRs7SpKUlOSoU6eO4+9//7vH/F69epnvrLMsN7ItVG408aDc0irokkbz6NmlWr169U13ZtSzSD1zv1Evv/yyqZFw0rPDOnXqeDQ/3A66fR8fH3NG6k5rLzST6BmsO63VqV+/vuu+njVrc8E333xz3efR5iutKXDvi6HPq8OKtbnEW1orou+P1p78/e9/d036PA0aNDC1Qk46b/bs2aa2QmuVtGZKmw607OrcuXOmj5JuSz8bzm1pTZiOADt69KipvXCnNXC675x02/pYrX3R5iF3JQ1j18+b1sDo44ujtU1abm3OcH+t+n5o8+D27duLfezNlku519798MMPkpOTY8rxxRdfeJT/et8XXefbb7+VvXv3FrlcP2taS9W1a1fzf/fXqPtfn9f5nNfbFkBAQbmlB0T3MFDYCy+8YKr6tclAm2a0mUar+r0JK9pM4E2HWD2gFj5waB+D6/W/uFXaH0eHYRfeH9rc4lzuTpsWCtODph68rvc8+hqrVq16Q89zIzQ06MFMt6vNAe6TNpFoU5k7fR+1WWLPnj0mXGiTipM2Sei2tLmo8Laco4kKb0+bqdwdP37c3Gr/HG9oU9H9999vmgS1aUubYgr369HXqvMKl00DSlFlK41yKW3K0WYXDTbaL0efc+7cuSYwePN90aZLPTF49NFHzfs1aNAgjyYgbZrTpr758+df8xqdQd/5Gq+3LYA+KCiX9MxL/7jqwb+ks0Y9I9UzcO2sqQeGP/zhD6aTrfZdcT9rLmkbpa24s109g76RMpWG4p6ncIfan4MeAHWfaC1PUeXSg5g7rQ3Zt2+f+f/hw4fN452ByXkwfeONN8wZe1EKf2ZK6z3WTrZao6N9f/S16KQde7VWzdmJWMun/WfefPPNIrehAae0/fd//7fpf6L9eebMmWNq9LTWS8vm3iH1Rr4vGkTT09NN4NHlWlui29T+O9oXyLn/tb9WYmJikeVxXhrgetsCCCgol7QTpiruIOSkBy49w9ZJr52iIz7+7d/+zfwR1rPW0r7yrJ4hFz7g61m9+/VatKZCzzIL09qHe++913Xfm7LFxMTIli1bTBOAey2KjmZxLi8Nuh3tyOgeCm71ebSpSfeT1mTcyAFaz7T1daakpJiOotqxVDvOKuf+0wOws1biZsqjvvrqqxIDcFG0tk2bN3TSfaS1Kh988IGp0dFt6ba15u9mynaz5dIDv9acaHDSJksnDSjefl+UdjrW2hadtMNtjx49TCdnfS+0pkQ/fxq2b+Q1lrStws1YqHxo4kG5o30Mxo8fbw5oOiqhONofoTDnBc/y8vLMrfOaF0UFhpvx4YcfevSL0aGcOjpDq/3dDzS7du0yf5Cd9Cyy8HBkb8qmI1j0oPAf//EfHvN19I4GHffnvxX6PHrBPD2zdiooKDAjbrSmQ0eoeEsPSnp2rmfNhWtw9L7WmLjvT33u9957z/TF0GYIvUDfkSNHXLUYOspIQ4Hu98K0CeJ6OnXqZA6yGoB0ZEnh8hTHvZzOg70zmDo/b9o3ZufOnSYsFKbvs+7L0i6X7lv9DOjnw0mbHHWYubffl8KvUQOZXutGn18vpqjPpaPBNBRpkCpp/19vWwA1KLCaVpPr2bn+4dbhixpOtLOgnqnrdS1KOsvSoZJaZa39FXR9bfvWKmTtH6DXenCGBe2sN2/ePPPHX0NBq1atrumXcKO0fV+3re3tWl49u9ezXfeh0NrGrwfap556yhywtG+BXgPEvdOqt2XTM/Zf/OIX5mxXDz56bRKtltcOjzqss/C2b5YOedaDvw4r1uvD6HVA9LVo3wF9rSX1CSqOlm3ChAnmrFnLrsOBdTt6HZWVK1ea59QmG33/9LL5+jp1+KrSQKZn91oeHTqtoUA70ep7oNcg0f2utSr6Xmgw0KbBL7/8ssTyaIdbDXb6Puk1RnTIq9Z66eN0mLD7NV/c6fp6kNcmEf2MaY2YBjc9yDv76Oiwb/3c6nBeLbNej0Q71upwad2P+vrvvPPOUi2Xfv61NkQ/b/oY3Y+6j/RzqbVh3nxfNCRpR2Xtq6L9VLSPkL4H+hjne6/hUd8T/azq/tfQoftFO8dqLZ8zCN3ItlDJlfUwIqAoziGgzkmHxUZGRprhpTpk1304a3HDjNPS0sxQxrp165rH6+2LL754zRDP1atXO2JjY82QVvdhvTrkt7hhkMUNM/6v//ovR3JysiM8PNxRvXp1M8z25MmT1zz+/fffN0OS/f39HW3btnXs27fvmm2WVLaihpKeP3/eMXz4cPM6/fz8zJDaf//3f/cYgqp0O4MGDbqmTMUNfy4sMzPT0a9fP8edd95p9qsO6S1qKPSNDjN2+uMf/2iG/OowXJ0aNmxoypmenm6W9+jRwwyz1WHJhfeRvqZJkya55h0/ftzx8ssvm8+M7gvd188884zj448/vuGh7GvWrDFDk/V91OHDjz76qHl/nQq/B7rtTp06mfde94sOf37ttdfM0OjC75N+Ru677z6znu5HfZ4pU6aY4b/X42251MKFC83nQT9vul/1td/M9+WDDz5wPP74445atWqZbdWvX98xcuRIj2Hezs+IvndRUVFm/+v7oMO/58+f7/W2UHlV0X/KOiQBAAC4ow8KAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1yuWF2vQS0mfOnDEX8yntS5UDAIDbQ69solfb1h83LfyjoxUioGg4iYqKKutiAACAm6A/7aFXKa5wAcV5GWR9gXr5ZwAAYL/c3FxTwXAjP2dQLgOKs1lHwwkBBQCA8uVGumfQSRYAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdbz6NeMrV67I2LFjZcmSJZKRkSF169aVvn37yqhRo1y/TOhwOGTMmDGyYMECyc7OlrZt28rcuXOlQYMGru2cO3dOhgwZImvXrpWqVatKz549ZcaMGRIUFFT6rxAoJc8++6wcP3683O3P+vXry5o1a8q6GABw+wLKpEmTTNhYvHixNG7cWPbt2yf9+vWTkJAQef311806kydPlpkzZ5p16tWrJ++8844kJCTI4cOHJSAgwKzTu3dvOXv2rGzevFny8/PNNl599VVZunSpd6UHfkYaTg6nHxG/0LrlZr/nZ58p6yIAwE2p4tAqjxv0zDPPSEREhCxcuNA1T2s/qlevbmpVdFNaq/Kb3/xG3njjDbM8JyfHPGbRokXSq1cv+frrryU2Nlb27t0rLVu2NOts2LBBnn76afn222/N4wvLy8szk1Nubq5ERUWZbQcHB9/cKwe8pKH8aOYFqfvKnHKz7878v19Lg4ggOXToUFkXBQBEj99aqXEjx2+v+qC0adNG0tLS5MiRI+b+l19+KZ9//rl07tzZ3D9x4oRp+omPj3c9RgvSqlUr2blzp7mvt6Ghoa5wonR9berZvXt3kc+bkpJituOcNJwAAICKy6smnrffftukn4YNG4qPj4/pkzJx4kTTZKM0nCitMXGn953L9DY8PNyzEL6+EhYW5lqnsOTkZBkxYsQ1NSgAAKBi8iqgLF++XD766CPTV0Sruw8cOCDDhg0zzTKJiYm3rZD+/v5mAgAAlYNXAWXkyJGmFkX7kqimTZvKyZMnTROMBpTIyEgzPzMzU+rUqeN6nN5v3ry5+b+uk5WV5bHdgoICM7LH+XgAAFC5eRVQfvzxR9NXxJ029Vy9etX8X0ftaMjQfirOQKLNMdq3ZODAgeZ+XFycGX68f/9+adGihZm3detWsw3tqwLvMfwVAFCpA0rXrl1Nn5Po6GjTxPPXv/5Vpk6dKv379zfL9Voo2uQzYcIEc90T5zBjbQLq3r27WadRo0by1FNPyYABA2TevHlmmPHgwYNNrUxRI3hwfQx/BQBU6oAya9YsEzh+/etfm2YaDRSvvfaajB492rXOm2++KRcvXjTXNdGaknbt2plhxM5roCjtx6KhpGPHjq4Ltem1U3Dz9Noc5W34KwAApRJQatasKdOnTzdTcbQWZdy4cWYqjo7Y4aJsAACgOPwWDwAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAAAo31eSBQAAFf/HXFX9+vVlzZo1UlYIKAAA3Cbl8cdcVX72GSlrBBQAAG6j8vZjrrb8oCt9UAAAgHUIKAAAwDo08QBAJe0IWdadIIGSEFAAoBJ2hLShEyRQEgIKAFTCjpA2dIIESkIfFAAAYB0CCgAAsA5NPBWgs5spb1BEWRcDAIBSQ0CpCJ3d8vLEL6isSwEAQOkhoFSAzm4np/yyrIsAAECpog8KAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAJTvgHLPPfdIlSpVrpkGDRpkll+6dMn8v1atWhIUFCQ9e/aUzMxMj22cOnVKunTpIjVq1JDw8HAZOXKkFBQUlO6rAgAAlSeg7N27V86ePeuaNm/ebOY/99xz5nb48OGydu1aWbFihWzbtk3OnDkjPXr0cD3+ypUrJpxcvnxZduzYIYsXL5ZFixbJ6NGjS/t1AQCAyhJQateuLZGRka5p3bp1Ur9+fWnfvr3k5OTIwoULZerUqdKhQwdp0aKFpKammiCya9cu8/hNmzbJ4cOHZcmSJdK8eXPp3LmzjB8/XmbPnm1CCwAAgNcBxZ0GCg0a/fv3N808+/fvl/z8fImPj3et07BhQ4mOjpadO3ea+3rbtGlTiYiIcK2TkJAgubm5cujQoWKfKy8vz6zjPgEAgIrrpgPKqlWrJDs7W/r27WvuZ2RkSLVq1SQ0NNRjPQ0jusy5jns4cS53LitOSkqKhISEuKaoqKibLTYAACgHfG/2gdqco000devWldstOTlZRowY4bqvNSiEFACoXJ599lk5fvy4lCemvEGeJ+a4jQHl5MmTsmXLFvnTn/7kmqd9UrTZR2tV3GtRdBSPLnOus2fPHo9tOUf5ONcpir+/v5kAAJWXHuwPpx8Rv9Dbf2JcWvLz8sQvqKxLUYkCinZ+1SHCOiLHSTvF+vn5SVpamhlerNLT082w4ri4OHNfbydOnChZWVnm8UpHAgUHB0tsbGzpvCIAQIWl4aTuK3OkvDg55ZdlXYTKE1CuXr1qAkpiYqL4+v70cO0bkpSUZJpiwsLCTOgYMmSICSWtW7c263Tq1MkEkT59+sjkyZNNv5NRo0aZa6dQQwIAAG46oGjTjtaK6OidwqZNmyZVq1Y1NSg68kZH6MyZ81PS9fHxMUOTBw4caIJLYGCgCTrjxo3zthgAAKAC8zqgaC2Iw+EocllAQIC5polOxYmJiZH169d7+7QAAKAS4bd4AACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAED5DyjfffedvPTSS1KrVi2pXr26NG3aVPbt2+da7nA4ZPTo0VKnTh2zPD4+Xo4ePeqxjXPnzknv3r0lODhYQkNDJSkpSS5cuFA6rwgAAFSugPLDDz9I27Ztxc/PTz755BM5fPiwvP/++3LHHXe41pk8ebLMnDlT5s2bJ7t375bAwEBJSEiQS5cuudbRcHLo0CHZvHmzrFu3TrZv3y6vvvpq6b4yAABQbvl6s/KkSZMkKipKUlNTXfPq1avnUXsyffp0GTVqlHTr1s3M+/DDDyUiIkJWrVolvXr1kq+//lo2bNgge/fulZYtW5p1Zs2aJU8//bRMmTJF6tatW3qvDgAAVPwalDVr1phQ8dxzz0l4eLg89NBDsmDBAtfyEydOSEZGhmnWcQoJCZFWrVrJzp07zX291WYdZzhRun7VqlVNjUtR8vLyJDc312MCAAAVl1cB5ZtvvpG5c+dKgwYNZOPGjTJw4EB5/fXXZfHixWa5hhOlNSbu9L5zmd5quHHn6+srYWFhrnUKS0lJMUHHOWktDgAAqLi8CihXr16Vhx9+WN59911Te6L9RgYMGGD6m9xOycnJkpOT45pOnz59W58PAACUo4CiI3NiY2M95jVq1EhOnTpl/h8ZGWluMzMzPdbR+85lepuVleWxvKCgwIzsca5TmL+/vxnx4z4BAICKy6uAoiN40tPTPeYdOXJEYmJiXB1mNWSkpaW5lmt/Ee1bEhcXZ+7rbXZ2tuzfv9+1ztatW03tjPZVAQAA8GoUz/Dhw6VNmzamief555+XPXv2yPz5882kqlSpIsOGDZMJEyaYfioaWN555x0zMqd79+6uGpennnrK1TSUn58vgwcPNiN8GMEDAAC8DiiPPPKIrFy50vQJGTdunAkgOqxYr2vi9Oabb8rFixdN/xStKWnXrp0ZVhwQEOBa56OPPjKhpGPHjmb0Ts+ePc21UwAAALwOKOqZZ54xU3G0FkXDi07F0RE7S5cu5R0AAABF4rd4AACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAED5Dihjx46VKlWqeEwNGzZ0Lb906ZIMGjRIatWqJUFBQdKzZ0/JzMz02MapU6ekS5cuUqNGDQkPD5eRI0dKQUFB6b0iAABQ7vl6+4DGjRvLli1bftqA70+bGD58uPz5z3+WFStWSEhIiAwePFh69Oghf/nLX8zyK1eumHASGRkpO3bskLNnz8rLL78sfn5+8u6775bWawIAAJUtoGgg0YBRWE5OjixcuFCWLl0qHTp0MPNSU1OlUaNGsmvXLmndurVs2rRJDh8+bAJORESENG/eXMaPHy9vvfWWqZ2pVq1a6bwqAABQufqgHD16VOrWrSv33nuv9O7d2zTZqP3790t+fr7Ex8e71tXmn+joaNm5c6e5r7dNmzY14cQpISFBcnNz5dChQ8U+Z15enlnHfQIAABWXVwGlVatWsmjRItmwYYPMnTtXTpw4IY899picP39eMjIyTA1IaGiox2M0jOgypbfu4cS53LmsOCkpKabJyDlFRUV5U2wAAFCRm3g6d+7s+n+zZs1MYImJiZHly5dL9erV5XZJTk6WESNGuO5rDQohBQCAiuuWhhlrbcn9998vx44dM/1SLl++LNnZ2R7r6CgeZ58VvS08qsd5v6h+LU7+/v4SHBzsMQEAgIrrlgLKhQsX5Pjx41KnTh1p0aKFGY2TlpbmWp6enm76qMTFxZn7envw4EHJyspyrbN582YTOGJjY2+lKAAAoLI28bzxxhvStWtX06xz5swZGTNmjPj4+MiLL75o+oYkJSWZppiwsDATOoYMGWJCiY7gUZ06dTJBpE+fPjJ58mTT72TUqFHm2ilaSwIAAOB1QPn2229NGPnHP/4htWvXlnbt2pkhxPp/NW3aNKlataq5QJuOvNEROnPmzHE9XsPMunXrZODAgSa4BAYGSmJioowbN453AwAA3FxAWbZsWYnLAwICZPbs2WYqjta+rF+/3punBQAAlQy/xQMAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAAKlZAee+996RKlSoybNgw17xLly7JoEGDpFatWhIUFCQ9e/aUzMxMj8edOnVKunTpIjVq1JDw8HAZOXKkFBQU3EpRAABABXLTAWXv3r3ywQcfSLNmzTzmDx8+XNauXSsrVqyQbdu2yZkzZ6RHjx6u5VeuXDHh5PLly7Jjxw5ZvHixLFq0SEaPHn1rrwQAAFTugHLhwgXp3bu3LFiwQO644w7X/JycHFm4cKFMnTpVOnToIC1atJDU1FQTRHbt2mXW2bRpkxw+fFiWLFkizZs3l86dO8v48eNl9uzZJrQUJS8vT3Jzcz0mAABQcd1UQNEmHK0FiY+P95i/f/9+yc/P95jfsGFDiY6Olp07d5r7etu0aVOJiIhwrZOQkGBCx6FDh4p8vpSUFAkJCXFNUVFRN1NsAABQUQPKsmXL5IsvvjChobCMjAypVq2ahIaGeszXMKLLnOu4hxPncueyoiQnJ5vaGed0+vRpb4sNAADKEV9vVtZgMHToUNm8ebMEBATIz8Xf399MAACgcvCqBkWbcLKysuThhx8WX19fM2lH2JkzZ5r/a02I9iPJzs72eJyO4omMjDT/19vCo3qc953rAACAys2rgNKxY0c5ePCgHDhwwDW1bNnSdJh1/t/Pz0/S0tJcj0lPTzfDiuPi4sx9vdVtaNBx0hqZ4OBgiY2NLc3XBgAAKkMTT82aNaVJkyYe8wIDA801T5zzk5KSZMSIERIWFmZCx5AhQ0woad26tVneqVMnE0T69OkjkydPNv1ORo0aZTre0owD4Nlnn5Xjx4+Xqx1hyhvk2bcOwM8YUG7EtGnTpGrVquYCbTo8WEfozJkzx7Xcx8dH1q1bJwMHDjTBRQNOYmKijBs3rrSLAqAc0oP94fQj4hdaV8qL/Lw88Qsq61IAFcstB5TPPvvM4752ntVrmuhUnJiYGFm/fv2tPjWACkrDSd1Xfjqxsd3JKb8s6yIAFQ6/xQMAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAlO+AMnfuXGnWrJkEBwebKS4uTj755BPX8kuXLsmgQYOkVq1aEhQUJD179pTMzEyPbZw6dUq6dOkiNWrUkPDwcBk5cqQUFBSU3isCAACVK6Dcfffd8t5778n+/ftl37590qFDB+nWrZscOnTILB8+fLisXbtWVqxYIdu2bZMzZ85Ijx49XI+/cuWKCSeXL1+WHTt2yOLFi2XRokUyevTo0n9lAACg3PL1ZuWuXbt63J84caKpVdm1a5cJLwsXLpSlS5ea4KJSU1OlUaNGZnnr1q1l06ZNcvjwYdmyZYtERERI8+bNZfz48fLWW2/J2LFjpVq1aqX76gAAQOXqg6K1IcuWLZOLFy+aph6tVcnPz5f4+HjXOg0bNpTo6GjZuXOnua+3TZs2NeHEKSEhQXJzc121MEXJy8sz67hPAACg4vI6oBw8eND0L/H395d//dd/lZUrV0psbKxkZGSYGpDQ0FCP9TWM6DKlt+7hxLncuaw4KSkpEhIS4pqioqK8LTYAAKjIAeWBBx6QAwcOyO7du2XgwIGSmJhomm1up+TkZMnJyXFNp0+fvq3PBwAAylEfFKW1JPfdd5/5f4sWLWTv3r0yY8YMeeGFF0zn1+zsbI9aFB3FExkZaf6vt3v27PHYnnOUj3OdomhtjU4AAKByuOXroFy9etX0EdGw4ufnJ2lpaa5l6enpZlix9lFReqtNRFlZWa51Nm/ebIYsazMRAACA1zUo2tTSuXNn0/H1/PnzZsTOZ599Jhs3bjR9Q5KSkmTEiBESFhZmQseQIUNMKNERPKpTp04miPTp00cmT55s+p2MGjXKXDuFGhIAAHBTAUVrPl5++WU5e/asCSR60TYNJ08++aRZPm3aNKlataq5QJvWqugInTlz5rge7+PjI+vWrTN9VzS4BAYGmj4s48aN86YYAACggvMqoOh1TkoSEBAgs2fPNlNxYmJiZP369d48LQAAqGT4LR4AAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAUL4DSkpKijzyyCNSs2ZNCQ8Pl+7du0t6errHOpcuXZJBgwZJrVq1JCgoSHr27CmZmZke65w6dUq6dOkiNWrUMNsZOXKkFBQUlM4rAgAAlSugbNu2zYSPXbt2yebNmyU/P186deokFy9edK0zfPhwWbt2raxYscKsf+bMGenRo4dr+ZUrV0w4uXz5suzYsUMWL14sixYtktGjR5fuKwMAAOWWrzcrb9iwweO+BgutAdm/f788/vjjkpOTIwsXLpSlS5dKhw4dzDqpqanSqFEjE2pat24tmzZtksOHD8uWLVskIiJCmjdvLuPHj5e33npLxo4dK9WqVSvdVwgAACpXHxQNJCosLMzcalDRWpX4+HjXOg0bNpTo6GjZuXOnua+3TZs2NeHEKSEhQXJzc+XQoUNFPk9eXp5Z7j4BAICK66YDytWrV2XYsGHStm1badKkiZmXkZFhakBCQ0M91tUwosuc67iHE+dy57Li+r6EhIS4pqioqJstNgAAqMgBRfuifPXVV7Js2TK53ZKTk01tjXM6ffr0bX9OAABQTvqgOA0ePFjWrVsn27dvl7vvvts1PzIy0nR+zc7O9qhF0VE8usy5zp49ezy25xzl41ynMH9/fzMBAIDKwasaFIfDYcLJypUrZevWrVKvXj2P5S1atBA/Pz9JS0tzzdNhyDqsOC4uztzX24MHD0pWVpZrHR0RFBwcLLGxsbf+igAAQOWqQdFmHR2hs3r1anMtFGefEe0XUr16dXOblJQkI0aMMB1nNXQMGTLEhBIdwaN0WLIGkT59+sjkyZPNNkaNGmW2TS0JAADwOqDMnTvX3D7xxBMe83Uocd++fc3/p02bJlWrVjUXaNPRNzpCZ86cOa51fXx8TPPQwIEDTXAJDAyUxMREGTduHO8IAADwPqBoE8/1BAQEyOzZs81UnJiYGFm/fr03Tw0AACoRfosHAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAJT/gLJ9+3bp2rWr1K1bV6pUqSKrVq3yWO5wOGT06NFSp04dqV69usTHx8vRo0c91jl37pz07t1bgoODJTQ0VJKSkuTChQu3/moAAEDlDCgXL16UBx98UGbPnl3k8smTJ8vMmTNl3rx5snv3bgkMDJSEhAS5dOmSax0NJ4cOHZLNmzfLunXrTOh59dVXb+2VAACACsPX2wd07tzZTEXR2pPp06fLqFGjpFu3bmbehx9+KBEREaampVevXvL111/Lhg0bZO/evdKyZUuzzqxZs+Tpp5+WKVOmmJoZAABQuZVqH5QTJ05IRkaGadZxCgkJkVatWsnOnTvNfb3VZh1nOFG6ftWqVU2NS1Hy8vIkNzfXYwIAABVXqQYUDSdKa0zc6X3nMr0NDw/3WO7r6ythYWGudQpLSUkxQcc5RUVFlWaxAQCAZcrFKJ7k5GTJyclxTadPny7rIgEAgPISUCIjI81tZmamx3y971ymt1lZWR7LCwoKzMge5zqF+fv7mxE/7hMAAKi4SjWg1KtXz4SMtLQ01zztL6J9S+Li4sx9vc3Ozpb9+/e71tm6datcvXrV9FUBAADwehSPXq/k2LFjHh1jDxw4YPqQREdHy7Bhw2TChAnSoEEDE1jeeecdMzKne/fuZv1GjRrJU089JQMGDDBDkfPz82Xw4MFmhA8jeAAAwE0FlH379skvfvEL1/0RI0aY28TERFm0aJG8+eab5lopel0TrSlp166dGVYcEBDgesxHH31kQknHjh3N6J2ePXuaa6cAAADcVEB54oknzPVOiqNXlx03bpyZiqO1LUuXLuUdAAAA5XcUDwAAqFwIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA65RpQJk9e7bcc889EhAQIK1atZI9e/aUZXEAAEBlDyh/+MMfZMSIETJmzBj54osv5MEHH5SEhATJysoqqyIBAIDKHlCmTp0qAwYMkH79+klsbKzMmzdPatSoIb///e/LqkgAAMASVRwOh+PnftLLly+bMPLxxx9L9+7dXfMTExMlOztbVq9e7bF+Xl6emZxycnIkOjpaTp8+LcHBwaVatkcffVTSjx4T35A6Ul4U/PCtSFWf8lXmnLNSzddH6tWrJ+XFiRMn5HLBFfYz+/kafAf5Dlakz4bzb/QDDe4r9a4Xubm5EhUVZY71ISEhJa/sKAPfffedhiLHjh07POaPHDnS8eijj16z/pgxY8z6TOwDPgN8BvgM8BngMyDlfh+cPn36ulnBV8qB5ORk01/F6erVq3Lu3DmpVauWVKlS5baku9tRO1PRsK/YV3yu+A6WF/y9smN/aaPN+fPnpW7dutddt0wCyp133ik+Pj6SmZnpMV/vR0ZGXrO+v7+/mdyFhobe1jLqG0JAYV/xuSo7fAfZV3yuKub38LpNO2XZSbZatWrSokULSUtL86gV0ftxcXFlUSQAAGCRMmvi0SYb7RTbsmVL0zF1+vTpcvHiRTOqBwAAVG5lFlBeeOEF+f7772X06NGSkZEhzZs3lw0bNkhERISUJW1K0muzFG5SAvuKzxXfQdvw94p9VZE/W2UyzBgAAKAk/BYPAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFD+z/bt26Vr167m8rt6+fxVq1aV7TtjqZSUFHnkkUekZs2aEh4ebn7sMT09vayLZa25c+dKs2bNXFdj1AsRfvLJJ2VdLOu999575ns4bNiwsi6KlcaOHWv2j/vUsGHDsi6Wtb777jt56aWXzM+jVK9eXZo2bSr79u0r62JZ55577rnmc6XToEGDyqQ8BJT/oxeJe/DBB2X27Nll8kaUF9u2bTMf1l27dsnmzZslPz9fOnXqZPYfrnX33Xebg+3+/fvNH8QOHTpIt27d5NChQ+yuYuzdu1c++OADE+xQvMaNG8vZs2dd0+eff87uKsIPP/wgbdu2FT8/P3NycPjwYXn//ffljjvuYH8V8d1z/0zp33j13HPPSVkoFz8W+HPo3LmzmVAyvZieu0WLFpmaFD0AP/744+y+QrRWzt3EiRNNrYoGPD3AwNOFCxekd+/esmDBApkwYQK7pwS+vr5F/nYZPE2aNMn86F1qaqprXr169dhNRahdu7bHfT25ql+/vrRv317KAjUouCU5OTnmNiwsjD15HVeuXJFly5aZ2iZ+c6poWjvXpUsXiY+P5/N0HUePHjVN0vfee68JdadOnWKfFWHNmjXmJ1W0FkBPph566CETgFGyy5cvy5IlS6R///6mmacsUIOCm6Y/8Kh9BLT6tEmTJuzJYhw8eNAEkkuXLklQUJCsXLlSYmNj2V+FaHj74osvTDUzStaqVStTe/nAAw+Yqvjf/e538thjj8lXX31l+ofhJ998842ptdTff/vtb39rPl+vv/66+dFa/T04FE37YWZnZ0vfvn2lrBBQcEtnu/oHkbbvkulB5MCBA6a26eOPPzZ/FLUvDyHlJ6dPn5ahQ4eaNu+AgAC+ldfh3hytfXU0sMTExMjy5cslKSmJ/VfoREprUN59911zX2tQ9O/WvHnzCCglWLhwofmcaS1dWaGJBzdl8ODBsm7dOvn0009NR1AUT8/U7rvvPmnRooUZBaWdsWfMmMEuc6N9mLKysuThhx82fSt00hA3c+ZM839tHkPxQkND5f7775djx46xmwqpU6fONScDjRo1okmsBCdPnpQtW7bIK6+8ImWJGhR4RX9bcsiQIaaZ4rPPPqOz2U2e0eXl5fHJc9OxY0fTFOauX79+ZujsW2+9JT4+Puyv63QuPn78uPTp04f9VIg2QRe+FMKRI0dMjROKph2Ktb+O9gcrSwQUty+4+9nHiRMnTLW8dv6Mjo4uq/fHymadpUuXyurVq01bd0ZGhpkfEhJiri8AT8nJyaaaVD9D58+fN/tOg93GjRvZVW70s1S4H1NgYKC5bgX9m671xhtvmBFiepA9c+aMjBkzxoS4F198kc9VIcOHD5c2bdqYJp7nn39e9uzZI/PnzzcTij6B0oCiTdFae1mmHDA+/fRTh+6OwlNiYiJ7yE1R+0in1NRU9lMR+vfv74iJiXFUq1bNUbt2bUfHjh0dmzZtYl/dgPbt2zuGDh3KvirCCy+84KhTp475XN11113m/rFjx9hXxVi7dq2jSZMmDn9/f0fDhg0d8+fPZ18VY+PGjeZvenp6uqOsVdF/yjYiAQAAeKKTLAAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAADENv8f/goZUKjicdEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Total number of features: 1432\n",
      "        act_x_mean    act_x_std    act_x_min    act_x_max   act_y_mean  \\\n",
      "count  4923.000000  4923.000000  4923.000000  4923.000000  4923.000000   \n",
      "mean     -0.043738     0.084839    -0.213862     0.125889     0.021000   \n",
      "std       0.632451     0.101467     0.670711     0.659041     0.591164   \n",
      "min      -1.005330     0.000000    -2.515625    -0.984375    -0.990820   \n",
      "25%      -0.604490     0.013705    -0.796875    -0.390625    -0.507964   \n",
      "50%      -0.062713     0.043409    -0.218750     0.000000    -0.008859   \n",
      "75%       0.587679     0.116063     0.406250     0.750000     0.597501   \n",
      "max       0.936497     0.550262     0.921875     2.984375     0.923908   \n",
      "\n",
      "         act_y_std    act_y_min    act_y_max   act_z_mean    act_z_std  ...  \\\n",
      "count  4923.000000  4923.000000  4923.000000  4923.000000  4923.000000  ...   \n",
      "mean      0.088973    -0.157205     0.193841     0.019937     0.093891  ...   \n",
      "std       0.106229     0.622982     0.600048     0.345142     0.130435  ...   \n",
      "min       0.002051    -1.796875    -0.968750    -0.995115     0.000973  ...   \n",
      "25%       0.018844    -0.750000    -0.218750    -0.175091     0.020902  ...   \n",
      "50%       0.041786    -0.140625     0.156250     0.029399     0.037130  ...   \n",
      "75%       0.113913     0.453125     0.796875     0.175106     0.092968  ...   \n",
      "max       0.543715     0.875000     1.640625     0.956803     0.641207  ...   \n",
      "\n",
      "       depth_pixel_187_mean  depth_pixel_187_std  depth_pixel_188_mean  \\\n",
      "count           4923.000000          4923.000000           4923.000000   \n",
      "mean               0.919738             0.019056              0.922443   \n",
      "std                0.060463             0.064629              0.045375   \n",
      "min                0.303888             0.000000              0.474457   \n",
      "25%                0.903545             0.000234              0.898020   \n",
      "50%                0.934469             0.000562              0.932708   \n",
      "75%                0.952647             0.000822              0.953278   \n",
      "max                0.977655             0.451566              0.976415   \n",
      "\n",
      "       depth_pixel_188_std  depth_pixel_189_mean  depth_pixel_189_std  \\\n",
      "count          4923.000000           4923.000000          4923.000000   \n",
      "mean              0.012359              0.925013             0.004840   \n",
      "std               0.052472              0.035296             0.032135   \n",
      "min               0.000000              0.634057             0.000000   \n",
      "25%               0.000104              0.896076             0.000107   \n",
      "50%               0.000452              0.931400             0.000449   \n",
      "75%               0.000762              0.953041             0.000751   \n",
      "max               0.426266              0.975411             0.373070   \n",
      "\n",
      "       depth_pixel_190_mean  depth_pixel_190_std  depth_pixel_191_mean  \\\n",
      "count           4923.000000          4923.000000           4923.000000   \n",
      "mean               0.919660             0.002947              0.915507   \n",
      "std                0.033503             0.019427              0.039380   \n",
      "min                0.743914             0.000000              0.531245   \n",
      "25%                0.889503             0.000145              0.885676   \n",
      "50%                0.926698             0.000432              0.923784   \n",
      "75%                0.948605             0.000745              0.945767   \n",
      "max                0.972376             0.230747              0.976495   \n",
      "\n",
      "       depth_pixel_191_std  \n",
      "count          4923.000000  \n",
      "mean              0.004648  \n",
      "std               0.034925  \n",
      "min               0.000000  \n",
      "25%               0.000270  \n",
      "50%               0.000512  \n",
      "75%               0.000720  \n",
      "max               0.433046  \n",
      "\n",
      "[8 rows x 1432 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Do more exploration and visualization of the data here\n",
    "\n",
    "# View headers \n",
    "print(list(train_df))\n",
    "\n",
    "# Analyze subject IDs and exercise (ground truth) values\n",
    "y_train = train_df.exercise.values\n",
    "sub_ids = train_df.subject_id.values\n",
    "\n",
    "print(\"\\nExamples of subject IDs : \", sub_ids[np.random.randint(0, len(sub_ids), 5)])\n",
    "\n",
    "# Histograms\n",
    "# TODO: make more cleaner looking histograms\n",
    "fig = plt.Figure(figsize=(10, 5))\n",
    "\n",
    "fig.add_subplot(2, 1, 1)\n",
    "plt.hist(y_train, edgecolor='black', linewidth=1.2)\n",
    "plt.title(\"Distribution of exercise classes\")\n",
    "plt.show()\n",
    "\n",
    "fig.add_subplot(2, 1, 2)\n",
    "plt.hist(sub_ids, edgecolor='black', linewidth=1.2)\n",
    "plt.title(\"Distribution of samples per subjects\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "total_number_of_features = len(acc_act_cols) + len(acc_acw_cols) + len(pressure_cols) + len(depth_cols)\n",
    "print(f\"\\n1. Total number of features: {total_number_of_features}\")\n",
    "\n",
    "\n",
    "columns_to_drop = ['subject_id', 'exercise']\n",
    "train_df_feats = train_df.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "pressure_cols\n",
    "\n",
    "# Plot the first image from depth camera std\n",
    "#pressure_mat_first = train_df[depth_std_cols].iloc[0].values\n",
    "#depth_std_image = depth_std_example.reshape(12, 16)\n",
    "#plt.imshow(depth_std_image, cmap='viridis', aspect='auto')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Task 2.</b> (3 Points)\n",
    "\n",
    "**Your task:** Prepare the data for modeling. Consider what preprocessing steps and feature engineering might improve classification performance. Common approaches include normalization, dimensionality reduction (PCA, LDA), feature selection, or creating new features. Document your choices and rationale in the report.\n",
    "\n",
    "*Hint: The objects/transformers you create here can be used in Task 3.*\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "import sys\n",
    "from sklearn.base import clone\n",
    "from scipy.stats import mode\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def make_pipelines_early_fusion_pca_sfs():\n",
    "    clf_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=0.9)),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, C=0.1, class_weight=\"balanced\"))\n",
    "    ])\n",
    "\n",
    "    # Forward feature selection using the pipeline as estimator\n",
    "    sfs = SFS(\n",
    "        clf_pipeline,\n",
    "        n_features_to_select=2,\n",
    "        direction=\"forward\",\n",
    "        scoring='f1_macro',\n",
    "        cv=3,   # internal CV\n",
    "        n_jobs=None\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([ (\"sfs\", sfs)])\n",
    "    return {\"logreg\" : pipe}\n",
    "\n",
    "def make_pipelines_logreg_svms_pca():\n",
    "    # Pipeline with logistic regression and different SVM variants\n",
    "        return {\n",
    "        \"logreg\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                C=0.1,\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]),\n",
    "        \"svc-linear\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"rbf\",\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]),\n",
    "        \"svc-rbf\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"linear\",\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]),\n",
    "        \"svc-poly\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"poly\",\n",
    "                degree = 3,\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]) }\n",
    "\n",
    "def make_pipelines_pca():\n",
    "    return {\n",
    "        \"logreg\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                C=0.1,\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]),\n",
    "        \"gnb\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),  # optional but recommended\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", GaussianNB()),\n",
    "        ]),\n",
    "        \"ada\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", AdaBoostClassifier(\n",
    "                n_estimators=50,\n",
    "                random_state=0\n",
    "            ))\n",
    "        ]),\n",
    "        \"svc\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"linear\",\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "def make_base_classification_pipelines():\n",
    "    return {\n",
    "        \"logreg\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                C=0.1,\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]),\n",
    "        \"gnb\": Pipeline([\n",
    "            # No scaler on purpose\n",
    "            (\"clf\", GaussianNB())\n",
    "        ]),\n",
    "        \"ada\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", AdaBoostClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=0\n",
    "            ))\n",
    "        ]),\n",
    "        \"svc\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"linear\",\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "def early_fusion_approach(X_train, y_train, X_test, y_test, approach):\n",
    "\n",
    "    if approach == 1:\n",
    "        pipelines = make_base_classification_pipelines()\n",
    "    elif approach == 2:\n",
    "        pipelines = make_pipelines_pca()\n",
    "    elif approach == 3:\n",
    "        pipelines = make_pipelines_early_fusion_pca_sfs()\n",
    "\n",
    "    scores = {\n",
    "    \"logreg\": 0.0,\n",
    "    \"gnb\": 0.0,\n",
    "    \"ada\": 0.0,\n",
    "    \"svc\": 0.0\n",
    "    }\n",
    "    for name, pipe in pipelines.items():\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_hat = pipe.predict(X_test)\n",
    "        scores[name] = f1_score(y_test, y_hat, average=\"macro\")\n",
    "\n",
    "    return scores[\"logreg\"], scores[\"gnb\"], scores[\"ada\"], scores[\"svc\"]\n",
    "\n",
    "def borda_count(preds):\n",
    "    # Borda count for class labels\n",
    "    y_final = []\n",
    "    for i in range(preds.shape[1]):\n",
    "        votes = preds[:, i]\n",
    "        counts = Counter(votes)\n",
    "        y_final.append(counts.most_common(1)[0][0])\n",
    "    return np.array(y_final)\n",
    "\n",
    "def aggregate_predictions(preds, strategy):\n",
    "    \"\"\"\n",
    "    preds: ndarray of shape (n_modalities, n_samples)\n",
    "    \"\"\"\n",
    "    if strategy == \"majority\":\n",
    "        return mode(preds, axis=0).mode.ravel()\n",
    "\n",
    "    elif strategy == \"borda\":\n",
    "        # Borda count for class labels\n",
    "        return borda_count(preds)\n",
    "\n",
    "\n",
    "def late_fusion_approach(X_train, y_train, X_test, y_test, feat_names, approach):\n",
    "    # Function to test late fusion approaches\n",
    "\n",
    "    # Split data according to modality\n",
    "    modalities = [\"act\", \"acw\", \"pressure\", \"depth\"]\n",
    "    X_modalities = split_data_based_on_modality(X_train, X_test, feat_names)\n",
    "    pipelines = make_pipelines_pca()  #make_base_classification_pipelines()\n",
    "    best_scores = {clf: -np.inf for clf in pipelines}\n",
    "    best_agg = {clf: None for clf in pipelines}\n",
    "\n",
    "    if approach == 4:\n",
    "\n",
    "        if approach == 4:\n",
    "            aggregations = [\"majority\", \"borda\"]\n",
    "        elif approach == 5:\n",
    "            aggregations = [\"borda\"]\n",
    "\n",
    "        for clf_name, base_pipe in pipelines.items():\n",
    "            modality_preds = []\n",
    "\n",
    "            for modality in [\"act\", \"acw\", \"pressure\", \"depth\"]:\n",
    "                X_tr = X_modalities[f\"{modality}_train\"]\n",
    "                X_te = X_modalities[f\"{modality}_test\"]\n",
    "\n",
    "                pipe = clone(base_pipe)   # IMPORTANT\n",
    "                pipe.fit(X_tr, y_train)\n",
    "\n",
    "                y_hat = pipe.predict(X_te)\n",
    "                modality_preds.append(y_hat)\n",
    "\n",
    "            # shape: (n_modalities, n_samples)\n",
    "            modality_preds = np.vstack(modality_preds)\n",
    "\n",
    "            # test aggregation strategies\n",
    "            for agg in aggregations:\n",
    "                y_fused = aggregate_predictions(modality_preds, agg)\n",
    "                f1 = f1_score(y_test, y_fused, average=\"macro\")\n",
    "\n",
    "                if f1 > best_scores[clf_name]:\n",
    "                    best_scores[clf_name] = f1\n",
    "                    best_agg[clf_name] = agg\n",
    "\n",
    "    elif approach == 5:\n",
    "\n",
    "        for clf_name, base_pipe in pipelines.items():\n",
    "            modality_preds = []\n",
    "\n",
    "            for modality in [\"act\", \"acw\", \"pressure\", \"depth\"]:\n",
    "                X_tr = X_modalities[f\"{modality}_train\"]\n",
    "                X_te = X_modalities[f\"{modality}_test\"]\n",
    "\n",
    "                pipe = clone(base_pipe)   # IMPORTANT\n",
    "                pipe.fit(X_tr, y_train)\n",
    "\n",
    "                y_hat = pipe.predict(X_te)\n",
    "                modality_preds.append(y_hat)\n",
    "\n",
    "            # shape: (n_modalities, n_samples)\n",
    "            modality_preds = np.vstack(modality_preds)\n",
    "\n",
    "            y_fused = borda_count(modality_preds)\n",
    "            f1 = f1_score(y_test, y_fused, average=\"macro\")\n",
    "            best_scores[clf_name] = f1\n",
    "\n",
    "\n",
    "    return best_scores[\"logreg\"], best_scores[\"gnb\"], best_scores[\"ada\"], best_scores[\"svc\"], best_agg\n",
    "\n",
    "def split_data_based_on_modality(X_train, X_test, feat_names):\n",
    "    # INPUTS\n",
    "    # X_data : features\n",
    "    # y_data : labels\n",
    "    # feat_names : list\n",
    "\n",
    "    # OUTPUTS\n",
    "    # dictionary output of train-test data per modality\n",
    "\n",
    "    X_train = pd.DataFrame(X_train, columns=feat_names)\n",
    "    X_test  = pd.DataFrame(X_test, columns=feat_names)\n",
    "\n",
    "    \n",
    "    # Identify columns by modality\n",
    "    act_cols = [c for c in feat_names if c.startswith(\"act_\")]\n",
    "    acw_cols = [c for c in feat_names if c.startswith(\"acw_\")]\n",
    "    pressure_cols = [c for c in feat_names if c.startswith(\"pressure_mat_\")]\n",
    "    depth_cols = [c for c in feat_names if c.startswith(\"depth_\")]\n",
    "\n",
    "    # Split features\n",
    "    X_train_act = X_train[act_cols].values\n",
    "    X_test_act = X_test[act_cols].values\n",
    "\n",
    "    X_train_acw = X_train[acw_cols].values\n",
    "    X_test_acw = X_test[acw_cols].values\n",
    "\n",
    "    X_train_pressure = X_train[pressure_cols].values\n",
    "    X_test_pressure = X_test[pressure_cols].values\n",
    "\n",
    "    X_train_depth = X_train[depth_cols].values\n",
    "    X_test_depth = X_test[depth_cols].values\n",
    "\n",
    "    # Labels are the same for all modalities\n",
    "    return {\n",
    "        \"act_train\": X_train_act,\n",
    "        \"act_test\": X_test_act,\n",
    "        \"acw_train\": X_train_acw,\n",
    "        \"acw_test\": X_test_acw,\n",
    "        \"pressure_train\": X_train_pressure,\n",
    "        \"pressure_test\": X_test_pressure,\n",
    "        \"depth_train\": X_train_depth,\n",
    "        \"depth_test\": X_test_depth\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature selection, fusion and model development and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task3'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Task 3.</b> (10 Points)\n",
    "\n",
    "**Your task:** Develop and evaluate a user-independent exercise classifier\n",
    "\n",
    "Experiment with:\n",
    "- At least **two different fusion strategies** (e.g., early fusion (feature level), late fusion (decision level), intermediate level (eg. kernel level fusion), hybrid of any combination\n",
    "\n",
    "You could also experiment with:\n",
    "- Different classifiers and architectures\n",
    "- Various feature combinations\n",
    "\n",
    "In your report, document what you tried, explain your design choices, and present your best approach with confusion matrix and F1-score.\n",
    "\n",
    "**Important:** The approach you finalize here will be used for the held-out test set prediction in Task 4.\n",
    "\n",
    "*Hint: Consider using Leave-One-Subject-Out (LOSO) cross-validation. You might want to try some new things on task 2 based on the results here*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion strategies to test\n",
    "#\n",
    "# Approach 1 - utilize all features from all modalities with LOSO-CV - standardize data\n",
    "#\n",
    "# Approach 1 Avg. F1 macro scores\n",
    "# Logistic regression F1 score : 0.8694898412557795\n",
    "# Naive Bayes F1 score : 0.5214310306023093\n",
    "# AdaBoost F1 score : 0.33339218807885046\n",
    "# SVC F1 score : 0.8772841420545663\n",
    "# \n",
    "# NOTES\n",
    "# Adaboost only used 10 ensembles to speed up and thus likely under performed\n",
    "# Best model: SVC () kernel=\"linear\", class_weight=\"balanced\")\n",
    "# In next approach dimensionalities are reduced\n",
    "\n",
    "# Approach 2 - PCA dimensionality reduction with early fusion (PCs : 150)\n",
    "# Avg. F1 macro scores\n",
    "# Approach 2 Avg. F1 macro scores\n",
    "# Logistic regression F1 score : 0.8595427538322881\n",
    "# Naive Bayes F1 score : 0.3559731189093147\n",
    "# AdaBoost F1 score : 0.5266776969610779\n",
    "# SVC F1 score : 0.8359281966469453\n",
    "#\n",
    "# NOTES: \n",
    "# Best model is Logistic regression but it's weaker than in last round\n",
    "\n",
    "\n",
    "# Approach 3 - PCA with Logistic regression (variance explained = 90% + SFS feature selection)\n",
    "# Rationale : Logistic regression is fast and PCA dimensionality reduction makes it even faster\n",
    "# Let's try to mine from features that explain 90% of the variance the best ones with SFS\n",
    "\n",
    "\n",
    "# Late Fusion\n",
    "\n",
    "# Approach  4 - parallel apparoach : use accelerometer, video and pressure in parallel and conduct fusion as last step\n",
    "# Consider : SVC with different kernels (polynomial, RBF).\n",
    "# Majority vote and borda count are tested as combination strategies\n",
    "\n",
    "#Approach 4 Avg. F1 macro scores\n",
    "#Logistic regression F1 score : 0.8883773042132458\n",
    "#Naive Bayes F1 score : 0.8089168611761173\n",
    "#AdaBoost F1 score : 0.878568804266227\n",
    "#SVC F1 score : 0.8945082734387513\n",
    "# Borda selected 2/3 times across all.\n",
    "\n",
    "# Approach 5\n",
    "# Same as app 4 but we use borda count because it was superior in approach 4\n",
    "\n",
    "# Approach 5 Avg. F1 macro scores\n",
    "# Logistic regression F1 score : 0.8562715221592293\n",
    "# Naive Bayes F1 score : 0.7138920174519674\n",
    "# AdaBoost F1 score : 0.6335289245424124\n",
    "# SVC F1 score : 0.857413306641343\n",
    "\n",
    "# IDEA: test for each dataset the classification - find best model for each task\n",
    "\n",
    "\n",
    "#\n",
    "# NOTES from Miika:\n",
    "# 1 Project is sufficient in terms of classifiers.. Just put more fusion methods.. at least one more.. late fusion..\n",
    "# 2 Document in project report where the pre-process methods are (in pipelines)\n",
    "# 3 Windowing of data : 5 seconds with 2 sec overlap (more or less)\n",
    "#\n",
    "\n",
    "# Classifiers to test (typical)\n",
    "# Logistic Regression\n",
    "# Naive Bayes\n",
    "# SVM learners\n",
    "# AdaBoost\n",
    "\n",
    "# More classifiers\n",
    "# XGBoost?\n",
    "\n",
    "# Feature selection methods to test\n",
    "# PCA (select some of the components)\n",
    "# SFS\n",
    "\n",
    "# VALIDATION\n",
    "# LOSOCV for each approach defines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4923, 1432)\n",
      "Approach 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     54\u001b[39m     f1_logreg, f1_gnb, f1_ada, f1_svc = early_fusion_approach(X_valid, y_valid,\n\u001b[32m     55\u001b[39m                                                                X_valid_test, \n\u001b[32m     56\u001b[39m                                                                y_valid_test, approach)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     58\u001b[39m     \u001b[38;5;66;03m# Late fusion\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     f1_logreg, f1_gnb, f1_ada, f1_svc, best_agg = \u001b[43mlate_fusion_approach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m                                                             \u001b[49m\u001b[43mX_valid_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m                                                               \u001b[49m\u001b[43mfeat_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapproach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# Count best aggregation strategies across classifiers\u001b[39;00m\n\u001b[32m     64\u001b[39m     agg_counter.update(best_agg.values())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 197\u001b[39m, in \u001b[36mlate_fusion_approach\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, feat_names, approach)\u001b[39m\n\u001b[32m    194\u001b[39m X_te = X_modalities[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodality\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_test\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    196\u001b[39m pipe = clone(base_pipe)   \u001b[38;5;66;03m# IMPORTANT\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m y_hat = pipe.predict(X_te)\n\u001b[32m    200\u001b[39m modality_preds.append(y_hat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:655\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m     )\n\u001b[32m    654\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\joblib\\memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:466\u001b[39m, in \u001b[36mPCA.fit_transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    445\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[32m    446\u001b[39m \n\u001b[32m    447\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m \u001b[33;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     U, S, _, X, x_is_centered, xp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         U = U[:, : \u001b[38;5;28mself\u001b[39m.n_components_]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:540\u001b[39m, in \u001b[36mPCA._fit\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mfull\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcovariance_eigh\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_array_api_compliant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33marpack\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrandomized\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_truncated(X, n_components, xp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:640\u001b[39m, in \u001b[36mPCA._fit_full\u001b[39m\u001b[34m(self, X, n_components, xp, is_array_api_compliant)\u001b[39m\n\u001b[32m    637\u001b[39m     U = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;66;03m# flip eigenvectors' sign to enforce deterministic output\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m U, Vt = \u001b[43msvd_flip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_based_decision\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    642\u001b[39m components_ = Vt\n\u001b[32m    644\u001b[39m \u001b[38;5;66;03m# Get variance explained by singular values\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\Project files-20251125\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:946\u001b[39m, in \u001b[36msvd_flip\u001b[39m\u001b[34m(u, v, u_based_decision)\u001b[39m\n\u001b[32m    943\u001b[39m         v *= signs[:, np.newaxis]\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    945\u001b[39m     \u001b[38;5;66;03m# rows of v, columns of u\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m     max_abs_v_rows = xp.argmax(\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    947\u001b[39m     shift = xp.arange(v.shape[\u001b[32m0\u001b[39m], device=device(v))\n\u001b[32m    948\u001b[39m     indices = max_abs_v_rows + shift * v.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Approaches 1-4\n",
    "\n",
    "feat_names = train_df_feats.columns.tolist()\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "X_train = train_df_feats.values\n",
    "print(X_train.shape)\n",
    "\n",
    "#print(type(train_df))\n",
    "#print(train_df.columns)\n",
    "#print(train_df.info)\n",
    "#print(train_df.head)\n",
    "#train_df.tail()\n",
    "#sys.exit()\n",
    "\n",
    "#y_train = train_df.exercise.values\n",
    "#sub_ids = train_df.subject_id.values\n",
    "#train_df_feats\n",
    "\n",
    "# LOSO-CV validation\n",
    "\n",
    "n_folds = len(np.unique(sub_ids))\n",
    "\n",
    "# Experiments 1-3 : Early Fusion\n",
    "# Experiments 4- : Late Fusion\n",
    "\n",
    "approach = 5 # 1, 2, 3, 4... experiment number\n",
    "\n",
    "print(f\"Approach {approach}\")\n",
    "logreg_f1scs = np.zeros((n_folds, 1))\n",
    "gnb_f1scs = np.zeros((n_folds, 1))\n",
    "ada_f1scs = np.zeros((n_folds, 1))\n",
    "svc_f1scs = np.zeros((n_folds, 1))\n",
    "\n",
    "if approach == 4:\n",
    "    # Late fusion\n",
    "    strategies = [\"majority vote\", \"borda\"]\n",
    "    agg_counter = Counter()\n",
    "elif approach == 5:\n",
    "    strategies = [\"borda\"]\n",
    "    agg_counter = Counter()\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X_train, y_train, sub_ids)):\n",
    "    t_start = time.time()\n",
    "    X_valid = X_train[train_index, :]\n",
    "    y_valid = y_train[train_index]\n",
    "    X_valid_test = X_train[test_index, :]\n",
    "    y_valid_test = y_train[test_index]\n",
    "\n",
    "    # Early fusion : utilize all features from all modalities with LOSO-CV\n",
    "\n",
    "    if approach <= 3:\n",
    "        f1_logreg, f1_gnb, f1_ada, f1_svc = early_fusion_approach(X_valid, y_valid,\n",
    "                                                                   X_valid_test, \n",
    "                                                                   y_valid_test, approach)\n",
    "    else:\n",
    "        # Late fusion\n",
    "        f1_logreg, f1_gnb, f1_ada, f1_svc, best_agg = late_fusion_approach(X_valid, y_valid, \n",
    "                                                                 X_valid_test, y_valid_test,\n",
    "                                                                   feat_names, approach)\n",
    "        \n",
    "        # Count best aggregation strategies across classifiers\n",
    "        agg_counter.update(best_agg.values())\n",
    "\n",
    "    logreg_f1scs[i] = f1_logreg\n",
    "    gnb_f1scs[i] = f1_gnb\n",
    "    ada_f1scs[i] = f1_ada\n",
    "    svc_f1scs[i] = f1_svc\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        print(f\"Fold {i+1} \\\\ {n_folds} running average F1 scores\")\n",
    "        print(f\"Logistic regression F1 score : {np.mean(f1_logreg)}\")\n",
    "        print(f\"Naive Bayes F1 score : {np.mean(f1_gnb)}\")\n",
    "        print(f\"AdaBoost F1 score : {np.mean(f1_ada)}\")\n",
    "        print(f\"SVC F1 score : {np.mean(f1_svc)}\")\n",
    "        print(f\"Time taken : {round(time.time() - t_start)} seconds\")\n",
    "    \n",
    "print(f\"\\nApproach {approach} Avg. F1 macro scores\")\n",
    "print(f\"Logistic regression F1 score : {np.mean(logreg_f1scs)}\")\n",
    "print(f\"Naive Bayes F1 score : {np.mean(gnb_f1scs)}\")\n",
    "print(f\"AdaBoost F1 score : {np.mean(ada_f1scs)}\")\n",
    "print(f\"SVC F1 score : {np.mean(svc_f1scs)}\")\n",
    "\n",
    "if approach > 3:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar(agg_counter.keys(), agg_counter.values(), color='skyblue')\n",
    "    plt.xlabel('Aggregation Strategy')\n",
    "    plt.ylabel('Number of Wins')\n",
    "    plt.title('Aggregation Strategy Usage Across LOSO Folds')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4923, 1432)\n",
      "Approach 6.1\n",
      "Fold 1 \\ 25\n",
      "Fold 3 \\ 25\n",
      "Fold 5 \\ 25\n",
      "Fold 7 \\ 25\n",
      "Fold 9 \\ 25\n",
      "Fold 11 \\ 25\n",
      "Fold 13 \\ 25\n",
      "Fold 15 \\ 25\n",
      "Fold 17 \\ 25\n",
      "Fold 19 \\ 25\n",
      "Fold 21 \\ 25\n",
      "Fold 23 \\ 25\n",
      "Fold 25 \\ 25\n",
      "\n",
      "Approach 6.1 Avg. F1 macro scores for different feature subsets (act, acw, pressure, depth)\n",
      "Logistic regression F1 score : [0.56949285 0.35545426 0.35545426 0.60941154]\n",
      "Naive Bayes F1 score : [0.61934259 0.32970713 0.32970713 0.20630235]\n",
      "AdaBoost F1 score : [0.49134462 0.30873036 0.30873036 0.45584267]\n",
      "SVC F1 score : [0.66032761 0.3393448  0.3393448  0.57915143]\n",
      "Best classifier for ACT : SVC with f1 : 0.6559317273506693\n",
      "Best classifier for ACW : Logistic Regression with f1 : 0.3606128566321879\n",
      "Best classifier for Pressure mat : Logistic Regression with f1 : 0.3606128566321879\n",
      "Best classifier for Depth Camera : Logistic Regression with f1 : 0.6077135065605049\n"
     ]
    }
   ],
   "source": [
    "# Approach:\n",
    "# Give features to mixutre of experts\n",
    "# 1) Test which classifiers work best with corresponding features\n",
    "# 2) Then utilize these classifiers to these features\n",
    "# 3) Provide weights to each classifier based on performance at fusion level\n",
    "# For fusion tests will be done with SVM, lin reg, and ada boost\n",
    "\n",
    "# From now on, each approach gets its own cell for clarity\n",
    "\n",
    "# 6.1 - test Log reg, naive bayes, adaboost and svc with different feature stes\n",
    "# Best classifier for ACT : SVC with f1 : 0.6559317273506693\n",
    "# Best classifier for ACW : Logistic Regression with f1 : 0.3606128566321879\n",
    "# Best classifier for Pressure mat : Logistic Regression with f1 : 0.3606128566321879\n",
    "# Best classifier for Depth Camera : Logistic Regression with f1 : 0.6077135065605049\n",
    "    \n",
    "# 6.2 test log reg, svc-linear, svc-rbf, svc-linear\n",
    "# Best classifier for ACT : SVM linear with f1 : 0.8069062264251637\n",
    "# Best classifier for ACW : SVM linear with f1 : 0.41693192727754963\n",
    "# Best classifier for Pressure mat : SVM linear with f1 : 0.41693192727754963\n",
    "# Best classifier for Depth Camera : Logistic Regression with f1 : 0.607713506560504\n",
    "\n",
    "\n",
    "def mixutre_of_experts_baseline_mdl_evaluation(X_train, X_test, y_train, y_test,approach):\n",
    "\n",
    "    #pipelines = make_base_classification_pipelines()\n",
    "\n",
    "    if approach == 6.1:\n",
    "        pipelines = make_pipelines_pca()\n",
    "        \n",
    "        scores = {\n",
    "        \"logreg\": 0.0,\n",
    "        \"gnb\": 0.0,\n",
    "        \"ada\": 0.0,\n",
    "        \"svc\": 0.0\n",
    "        }\n",
    "        for name, pipe in pipelines.items():\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_hat = pipe.predict(X_test)\n",
    "            scores[name] = f1_score(y_test, y_hat, average=\"macro\")\n",
    "\n",
    "        return scores[\"logreg\"], scores[\"gnb\"], scores[\"ada\"], scores[\"svc\"]\n",
    "\n",
    "    elif approach == 6.2:\n",
    "        pipelines = make_pipelines_logreg_svms_pca()\n",
    "        scores = {\n",
    "        \"logreg\": 0.0,\n",
    "        \"svc-linear\": 0.0,\n",
    "        \"svc-poly\": 0.0,\n",
    "        \"svc-rbf\": 0.0\n",
    "        }\n",
    "\n",
    "        for name, pipe in pipelines.items():\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_hat = pipe.predict(X_test)\n",
    "            scores[name] = f1_score(y_test, y_hat, average=\"macro\")\n",
    "\n",
    "        return scores[\"logreg\"], scores[\"svc-linear\"], scores[\"svc-poly\"], scores[\"svc-rbf\"]\n",
    "\n",
    "feat_names = train_df_feats.columns.tolist()\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "X_train = train_df_feats.values\n",
    "print(X_train.shape)\n",
    "\n",
    "# Define here data \n",
    "mod_of_interest = [\"act\", \"acw\", \"pressure_mat\", \"depth\"]\n",
    "\n",
    "act_cols = [c for c in feat_names if c.startswith(\"act_\")]\n",
    "acw_cols = [c for c in feat_names if c.startswith(\"acw_\")]\n",
    "pressure_cols = [c for c in feat_names if c.startswith(\"pressure_mat_\")]\n",
    "depth_cols = [c for c in feat_names if c.startswith(\"depth_\")]\n",
    "\n",
    "\n",
    "# LOSO-CV validation\n",
    "n_folds = len(np.unique(sub_ids))\n",
    "\n",
    "approach = 6.1 # 1, 2, 3, 4... experiment number\n",
    "\n",
    "print(f\"Approach {approach}\")\n",
    "if approach == 6.1:\n",
    "    logreg_f1scs = np.zeros((n_folds, len(mod_of_interest)))\n",
    "    gnb_f1scs = np.zeros((n_folds, len(mod_of_interest)))\n",
    "    ada_f1scs = np.zeros((n_folds, len(mod_of_interest)))\n",
    "    svc_f1scs = np.zeros((n_folds, len(mod_of_interest)))\n",
    "elif approach == 6.2:\n",
    "    logreg_f1scs = np.zeros((n_folds, len(mod_of_interest)))\n",
    "    svc_lin_f1scs = np.zeros((n_folds, len(mod_of_interest)))\n",
    "    svc_poly_f1scs = np.zeros((n_folds, len(mod_of_interest)))\n",
    "    svc_rbf_f1scs = np.zeros((n_folds, len(mod_of_interest)))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X_train, y_train, sub_ids)):\n",
    "    t_start = time.time()\n",
    "    X_valid = X_train[train_index, :]\n",
    "    y_valid = y_train[train_index]\n",
    "    X_valid_test = X_train[test_index, :]\n",
    "    y_valid_test = y_train[test_index]\n",
    "\n",
    "    X_modality = split_data_based_on_modality(X_valid, X_valid_test, feat_names)\n",
    "\n",
    "    for j in range(0, len(mod_of_interest)):\n",
    "\n",
    "        if mod_of_interest[j] == \"act\":\n",
    "            X_valid = X_modality[\"act_train\"]\n",
    "            X_valid_test = X_modality[\"act_test\"]\n",
    "        elif mod_of_interest[j] == \"acw\":\n",
    "            X_valid = X_modality[\"acw_train\"]\n",
    "            X_valid_test = X_modality[\"acw_test\"]\n",
    "        elif mod_of_interest[j] == \"pressure\":\n",
    "            X_valid = X_modality[\"pressure_train\"]\n",
    "            X_valid_test = X_modality[\"pressure_test\"]\n",
    "        elif mod_of_interest[j] == \"depth\":\n",
    "            X_valid = X_modality[\"pressure_train\"]\n",
    "            X_valid_test = X_modality[\"pressure_test\"]\n",
    "\n",
    "\n",
    "\n",
    "        # Early fusion : utilize all features from all modalities with LOSO-CV\n",
    "        \n",
    "        f1_1, f1_2, f1_3, f1_4 = mixutre_of_experts_baseline_mdl_evaluation(\n",
    "                                                                    X_valid, X_valid_test, \n",
    "                                                                    y_valid, y_valid_test, approach\n",
    "                                                                    )\n",
    "        \n",
    "\n",
    "        if approach == 6.1:\n",
    "            logreg_f1scs[i][j] = f1_1\n",
    "            gnb_f1scs[i][j] = f1_2\n",
    "            ada_f1scs[i][j]  = f1_3\n",
    "            svc_f1scs[i][j]  = f1_4\n",
    "        elif approach == 6.2:\n",
    "            logreg_f1scs[i][j] = f1_1\n",
    "            svc_lin_f1scs[i][j] = f1_2\n",
    "            svc_poly_f1scs[i][j] = f1_3\n",
    "            svc_rbf_f1scs[i][j] = f1_4\n",
    "\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        print(f\"Fold {i+1} \\\\ {n_folds}\")\n",
    "\n",
    "\n",
    "if approach == 6.1:\n",
    "    print(f\"\\nApproach {approach} Avg. F1 macro scores for different feature subsets (act, acw, pressure, depth)\")\n",
    "    print(f\"Logistic regression F1 score : {np.mean(logreg_f1scs[:i, :], axis=0)}\")\n",
    "    print(f\"Naive Bayes F1 score : {np.mean(gnb_f1scs[:i, :], axis=0)}\")\n",
    "    print(f\"AdaBoost F1 score : {np.mean(ada_f1scs[:i, :], axis=0)}\")\n",
    "    print(f\"SVC F1 score : {np.mean(svc_f1scs[:i, :], axis=0)}\")\n",
    "\n",
    "    # Identify best base learners\n",
    "    classifs = [\"Logistic Regression\", \"Naive Bayes\", \"AdaBoost\", \"SVC\"]\n",
    "    best_act = np.mean(np.vstack((logreg_f1scs[:, 0], gnb_f1scs[:, 0], ada_f1scs[:,0], svc_f1scs[:, 0])).T, axis=0)\n",
    "    best_acw = np.mean(np.vstack((logreg_f1scs[:, 1], gnb_f1scs[:, 1], ada_f1scs[:,1], svc_f1scs[:, 1])).T, axis=0)\n",
    "    best_pressure = np.mean(np.vstack((logreg_f1scs[:, 2], gnb_f1scs[:, 2], ada_f1scs[:,2], svc_f1scs[:, 2])).T, axis=0)\n",
    "    best_depth = np.mean(np.vstack((logreg_f1scs[:, 3], gnb_f1scs[:, 3], ada_f1scs[:,3], svc_f1scs[:, 3])).T, axis=0)\n",
    "elif approach == 6.2:\n",
    "    print(f\"\\nApproach {approach} Avg. F1 macro scores for different feature subsets (act, acw, pressure, depth)\")\n",
    "    print(f\"Logistic regression F1 score : {np.mean(logreg_f1scs[:i, :], axis=0)}\")\n",
    "    print(f\"SVM linear F1 score : {np.mean(svc_lin_f1scs[:i, :], axis=0)}\")\n",
    "    print(f\"SVM Poly F1 score : {np.mean(svc_poly_f1scs[:i, :], axis=0)}\")\n",
    "    print(f\"SVM RBF F1 score : {np.mean(svc_rbf_f1scs[:i, :], axis=0)}\")\n",
    "\n",
    "    # Identify best base learners\n",
    "    classifs = [\"Logistic Regression\", \"SVM linear\", \"SVM Polynomial (order=3)\", \"SVM RBF\"]\n",
    "    best_act = np.mean(np.vstack((logreg_f1scs[:, 0], svc_lin_f1scs[:, 0], svc_poly_f1scs[:,0], svc_rbf_f1scs[:, 0])).T, axis=0)\n",
    "    best_acw = np.mean(np.vstack((logreg_f1scs[:, 1], svc_lin_f1scs[:, 1], svc_poly_f1scs[:,1], svc_rbf_f1scs[:, 1])).T, axis=0)\n",
    "    best_pressure = np.mean(np.vstack((logreg_f1scs[:, 2], svc_lin_f1scs[:, 2], svc_poly_f1scs[:,2], svc_rbf_f1scs[:, 2])).T, axis=0)\n",
    "    best_depth = np.mean(np.vstack((logreg_f1scs[:, 3], svc_lin_f1scs[:, 3], svc_poly_f1scs[:,3], svc_rbf_f1scs[:, 3])).T, axis=0)\n",
    "\n",
    "# ... to take classifs(np.argmax(best_act)) for the best classifier name\n",
    "# But first test output\n",
    "idx_best_act = np.argmax(best_act)\n",
    "idx_best_acw = np.argmax(best_acw)\n",
    "idx_best_pressure = np.argmax(best_pressure)\n",
    "idx_best_depth = np.argmax(best_depth)\n",
    "\n",
    "print(f\"Best classifier for ACT : {classifs[idx_best_act]} with f1 : {best_act[idx_best_act]}\")\n",
    "print(f\"Best classifier for ACW : {classifs[idx_best_acw]} with f1 : {best_acw[idx_best_acw]}\")\n",
    "print(f\"Best classifier for Pressure mat : {classifs[idx_best_pressure]} with f1 : {best_pressure[idx_best_pressure]}\")\n",
    "print(f\"Best classifier for Depth Camera : {classifs[idx_best_depth]} with f1 : {best_depth[idx_best_depth]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432\n",
      "(4923, 286)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "n_feats = X_train.shape[1]\n",
    "X_new = SelectKBest(f_classif, k=round(n_feats*0.2)).fit_transform(X_train, y_train)\n",
    "\n",
    "print(n_feats)\n",
    "print(X_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1908.08992\n",
    "\n",
    "#üìå What your current results are actually telling you\n",
    "#Modality\tInterpretation\n",
    "#ACT\t‚úî Working, strong baseline\n",
    "#Depth\t‚ö† Partially useful, needs dimensionality reduction\n",
    "#Pressure\t‚ùå Feature representation invalid\n",
    "#ACW\t‚ùå Either noisy or redundant with ACT\n",
    "\n",
    "#pixel_i_mean\n",
    "#pixel_i_std\n",
    "#for hundreds of pixels, independently.\n",
    "\n",
    "#Why this fails:\n",
    "#Pixel indices are not semantically aligned across subjects\n",
    "\n",
    "#Small posture shifts ‚Üí pixel-wise statistics change drastically\n",
    "\n",
    "#You‚Äôre forcing the classifier to learn spatial correspondence that does not exist\n",
    "\n",
    "#This is especially fatal in LOSO.\n",
    "\n",
    "#üëâ This explains:\n",
    "#Pressure mat ‚âà random\n",
    "#Depth ‚âà somewhat better (global structure helps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4923, 1432)\n",
      "Shape of X_meta (198, 28)\n",
      "Fold 1 \\ 25\n",
      "F! round : [0.01893939]\n",
      "F1 running average: 0.01893939393939394\n",
      "Shape of X_meta (165, 28)\n",
      "Shape of X_meta (234, 28)\n",
      "Fold 3 \\ 25\n",
      "F! round : [0.07926829]\n",
      "F1 running average: 0.04198452419238732\n",
      "Shape of X_meta (198, 28)\n",
      "Shape of X_meta (226, 28)\n",
      "Fold 5 \\ 25\n",
      "F! round : [0.]\n",
      "F1 running average: 0.025190714515432387\n",
      "Shape of X_meta (190, 28)\n",
      "Shape of X_meta (187, 28)\n",
      "Fold 7 \\ 25\n",
      "F! round : [0.142372]\n",
      "F1 running average: 0.03833222405677623\n",
      "Shape of X_meta (201, 28)\n",
      "Shape of X_meta (202, 28)\n",
      "Fold 9 \\ 25\n",
      "F! round : [0.]\n",
      "F1 running average: 0.02981395204415929\n",
      "Shape of X_meta (191, 28)\n",
      "Shape of X_meta (196, 28)\n",
      "Fold 11 \\ 25\n",
      "F! round : [0.14136905]\n",
      "F1 running average: 0.03794426579170808\n",
      "Shape of X_meta (192, 28)\n",
      "Shape of X_meta (192, 28)\n",
      "Fold 13 \\ 25\n",
      "F! round : [0.00416667]\n",
      "F1 running average: 0.03242719925965042\n",
      "Shape of X_meta (189, 28)\n",
      "Shape of X_meta (188, 28)\n",
      "Fold 15 \\ 25\n",
      "F! round : [0.015625]\n",
      "F1 running average: 0.029145239358363703\n",
      "Shape of X_meta (204, 28)\n",
      "Shape of X_meta (199, 28)\n",
      "Fold 17 \\ 25\n",
      "F! round : [0.]\n",
      "F1 running average: 0.025932650644922995\n",
      "Shape of X_meta (206, 28)\n",
      "Shape of X_meta (194, 28)\n",
      "Fold 19 \\ 25\n",
      "F! round : [0.]\n",
      "F1 running average: 0.024230858471773208\n",
      "Shape of X_meta (193, 28)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 147\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    137\u001b[39m     pipe = Pipeline([\n\u001b[32m    138\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m\"\u001b[39m, StandardScaler()),\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m#(\"feat_sel\", SelectKBest(f_classif, k=round(n_feats*0.2))),\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    144\u001b[39m         probability=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    145\u001b[39m     ))])\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m y_proba, y_hat, f1 = \u001b[43mtrain_expert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m                                              \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m probs.append(y_proba)\n\u001b[32m    151\u001b[39m f1_scores.append(f1)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mtrain_expert\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, pipe)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_expert\u001b[39m(X_train, X_test, y_train, y_test, pipe):\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m#pipelines = make_base_classification_pipelines()\u001b[39;00m\n\u001b[32m     50\u001b[39m     X_train = X_train\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     y_hat = pipe.predict(X_test)\n\u001b[32m     53\u001b[39m     y_proba = pipe.predict_proba(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:663\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    658\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    659\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    660\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    661\u001b[39m             all_params=params,\n\u001b[32m    662\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:258\u001b[39m, in \u001b[36mBaseLibSVM.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[LibSVM]\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    257\u001b[39m seed = rnd.randint(np.iinfo(\u001b[33m\"\u001b[39m\u001b[33mi\u001b[39m\u001b[33m\"\u001b[39m).max)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;28mself\u001b[39m.shape_fit_ = X.shape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\milvesma19\\OneDrive - University of Oulu and Oamk\\Oulun yliopisto courses\\Multi Modal Data Fusion\\Project\\multimodal-exercise-classification\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:336\u001b[39m, in \u001b[36mBaseLibSVM._dense_fit\u001b[39m\u001b[34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[39m\n\u001b[32m    322\u001b[39m libsvm.set_verbosity_wrap(\u001b[38;5;28mself\u001b[39m.verbose)\n\u001b[32m    324\u001b[39m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[32m    326\u001b[39m (\n\u001b[32m    327\u001b[39m     \u001b[38;5;28mself\u001b[39m.support_,\n\u001b[32m    328\u001b[39m     \u001b[38;5;28mself\u001b[39m.support_vectors_,\n\u001b[32m    329\u001b[39m     \u001b[38;5;28mself\u001b[39m._n_support,\n\u001b[32m    330\u001b[39m     \u001b[38;5;28mself\u001b[39m.dual_coef_,\n\u001b[32m    331\u001b[39m     \u001b[38;5;28mself\u001b[39m.intercept_,\n\u001b[32m    332\u001b[39m     \u001b[38;5;28mself\u001b[39m._probA,\n\u001b[32m    333\u001b[39m     \u001b[38;5;28mself\u001b[39m._probB,\n\u001b[32m    334\u001b[39m     \u001b[38;5;28mself\u001b[39m.fit_status_,\n\u001b[32m    335\u001b[39m     \u001b[38;5;28mself\u001b[39m._num_iter,\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m ) = \u001b[43mlibsvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass_weight_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[38;5;28mself\u001b[39m._warn_from_fit_status()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Approach:\n",
    "# Give features to mixutre of experts\n",
    "# Based on the experiment 6, we have our classifier architecture selected\n",
    "# Now we will try two things: 1) Using probabilities, 2) Using feature selection\n",
    "# and 3) Using final fusion weighted fusion\n",
    "#\n",
    "# Goal is to get deployable model and thus we want the architecture locked. That's why step 6\n",
    "# was important part of experimentation\n",
    "\n",
    "from feature_engine.selection import MRMR\n",
    "\n",
    "\n",
    "def make_pipelines_mixture_of_experts():\n",
    "        return {\n",
    "        \"logreg\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                C=0.1,\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]),\n",
    "        \"svc-linear\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"linear\",\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]),\n",
    "        \"svc-rbf\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"linear\",\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]),\n",
    "        \"svc-poly\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"linear\",\n",
    "                degree = 3,\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ]) }\n",
    "\n",
    "\n",
    "def train_expert(X_train, X_test, y_train, y_test, pipe):\n",
    "\n",
    "    #pipelines = make_base_classification_pipelines()\n",
    "    X_train = X_train\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_hat = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)\n",
    "    f1 = f1_score(y_test, y_hat, average=\"macro\")\n",
    "\n",
    "    return y_proba, y_hat, f1\n",
    "\n",
    "feat_names = train_df_feats.columns.tolist()\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "X_train = train_df_feats.values\n",
    "print(X_train.shape)\n",
    "\n",
    "# Define here data \n",
    "mod_of_interest = [\"act\", \"acw\", \"pressure_mat\", \"depth\"]\n",
    "\n",
    "act_cols = [c for c in feat_names if c.startswith(\"act_\")]\n",
    "acw_cols = [c for c in feat_names if c.startswith(\"acw_\")]\n",
    "pressure_cols = [c for c in feat_names if c.startswith(\"pressure_mat_\")]\n",
    "depth_cols = [c for c in feat_names if c.startswith(\"depth_\")]\n",
    "\n",
    "\n",
    "# LOSO-CV validation\n",
    "n_folds = len(np.unique(sub_ids))\n",
    "\n",
    "approach = 7\n",
    "f1_meta = np.zeros((n_folds, 1))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X_train, y_train, sub_ids)):\n",
    "    t_start = time.time()\n",
    "    X_valid = X_train[train_index, :]\n",
    "    y_valid = y_train[train_index]\n",
    "    X_valid_test = X_train[test_index, :]\n",
    "    y_valid_test = y_train[test_index]\n",
    "\n",
    "    X_modality = split_data_based_on_modality(X_valid, X_valid_test, feat_names)\n",
    "\n",
    "    probs = []\n",
    "    f1_scores = []\n",
    "    for j in range(0, len(mod_of_interest)):\n",
    "\n",
    "        if mod_of_interest[j] == \"act\":\n",
    "            X_valid = X_modality[\"act_train\"]\n",
    "            X_valid_test = X_modality[\"act_test\"]\n",
    "\n",
    "        elif mod_of_interest[j] == \"acw\":\n",
    "            X_valid = X_modality[\"acw_train\"]\n",
    "            X_valid_test = X_modality[\"acw_test\"]\n",
    "\n",
    "            clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"linear\",\n",
    "                class_weight=\"balanced\"\n",
    "            ))])\n",
    "\n",
    "        elif mod_of_interest[j] == \"pressure\":\n",
    "            X_valid = X_modality[\"pressure_train\"]\n",
    "            X_valid_test = X_modality[\"pressure_test\"]\n",
    "\n",
    "            clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"feat_sel\", SelectKBest(f_classif, k=round(n_feats*0.2))),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"linear\",\n",
    "                class_weight=\"balanced\"\n",
    "            ))])\n",
    "\n",
    "        elif mod_of_interest[j] == \"depth\":\n",
    "            X_valid = X_modality[\"depth_train\"]\n",
    "            X_valid_test = X_modality[\"depth_test\"]\n",
    "\n",
    "\n",
    "        n_feats = X_valid.shape[1]\n",
    "\n",
    "        if mod_of_interest[j] == \"depth\":\n",
    "            pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            #(\"feat_sel\", SelectKBest(f_classif, k=round(n_feats*0.2))),\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                C=0.1,\n",
    "                class_weight=\"balanced\"\n",
    "            ))])\n",
    "        else:\n",
    "            pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            #(\"feat_sel\", SelectKBest(f_classif, k=round(n_feats*0.2))),\n",
    "            (\"pca\", PCA(n_components=0.9)),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"linear\",\n",
    "                class_weight=\"balanced\",\n",
    "                probability=True\n",
    "            ))])\n",
    "        \n",
    "        y_proba, y_hat, f1 = train_expert(X_valid, X_valid_test, \n",
    "                                                      y_valid, y_valid_test, pipe)\n",
    "        \n",
    "        probs.append(y_proba)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # FUSION - Meta-learner\n",
    "    X_meta = np.concatenate(np.array(probs), axis=1)\n",
    "    print(f\"Shape of X_meta {X_meta.shape}\")\n",
    "\n",
    "    \"\"\"\n",
    "    n_feats = X_meta.shape[1]\n",
    "    pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"feat_sel\", SelectKBest(f_classif, k=round(n_feats*0.2))),\n",
    "    (\"clf\", SVC(\n",
    "        kernel=\"linear\",\n",
    "        class_weight=\"balanced\"\n",
    "    ))]) \n",
    "    pipe.fit(X_meta, y_valid)\n",
    "    y_hat = pipe.predict(X_valid_test)\n",
    "    \"\"\"\n",
    "\n",
    "    weights = np.array(f1_scores)\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    p_fused = sum(w * p for w, p in zip(weights, probs))\n",
    "    y_hat = np.argmax(p_fused, axis=1)\n",
    "\n",
    "    f1_meta[i] = f1_score(y_valid_test, y_hat, average=\"macro\")\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        print(f\"Fold {i+1} \\\\ {n_folds}\")\n",
    "        print(f\"F! round : {f1_meta[i] }\")\n",
    "        print(f\"F1 running average: {np.mean(f1_meta[:i+1])}\")\n",
    "\n",
    "\n",
    "print(\"Mean overall F1-macro score : \", np.mean(f1_meta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prediction of the held out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression F1 score : [0.56949285 0.35545426 0.35545426 0.60941154]\n",
      "SVM linear F1 score : [0.81345924 0.42182994 0.42182994 0.5080441 ]\n",
      "SVM Poly F1 score : [0.77005644 0.3585228  0.3585228  0.26433151]\n",
      "SVM RBF F1 score : [0.66032761 0.3393448  0.3393448  0.57915143]\n"
     ]
    }
   ],
   "source": [
    "    print(f\"Logistic regression F1 score : {np.mean(logreg_f1scs[:i, :], axis=0)}\")\n",
    "    print(f\"SVM linear F1 score : {np.mean(svc_lin_f1scs[:i, :], axis=0)}\")\n",
    "    print(f\"SVM Poly F1 score : {np.mean(svc_poly_f1scs[:i, :], axis=0)}\")\n",
    "    print(f\"SVM RBF F1 score : {np.mean(svc_rbf_f1scs[:i, :], axis=0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_act = \u001b[43mnp\u001b[49m.mean(np.vstack((logreg_f1scs[:, \u001b[32m0\u001b[39m], gnb_f1scs[:, \u001b[32m0\u001b[39m], ada_f1scs[:,\u001b[32m0\u001b[39m], svc_f1scs[:, \u001b[32m0\u001b[39m])).T, axis=\u001b[32m0\u001b[39m)\n\u001b[32m      2\u001b[39m best_acw = np.mean(np.vstack((logreg_f1scs[:, \u001b[32m1\u001b[39m], gnb_f1scs[:, \u001b[32m1\u001b[39m], ada_f1scs[:,\u001b[32m1\u001b[39m], svc_f1scs[:, \u001b[32m1\u001b[39m])).T, axis=\u001b[32m0\u001b[39m)\n\u001b[32m      3\u001b[39m best_pressure = np.mean(np.vstack((logreg_f1scs[:, \u001b[32m2\u001b[39m], gnb_f1scs[:, \u001b[32m2\u001b[39m], ada_f1scs[:,\u001b[32m2\u001b[39m], svc_f1scs[:, \u001b[32m2\u001b[39m])).T, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "best_act = np.mean(np.vstack((logreg_f1scs[:, 0], gnb_f1scs[:, 0], ada_f1scs[:,0], svc_f1scs[:, 0])).T, axis=0)\n",
    "best_acw = np.mean(np.vstack((logreg_f1scs[:, 1], gnb_f1scs[:, 1], ada_f1scs[:,1], svc_f1scs[:, 1])).T, axis=0)\n",
    "best_pressure = np.mean(np.vstack((logreg_f1scs[:, 2], gnb_f1scs[:, 2], ada_f1scs[:,2], svc_f1scs[:, 2])).T, axis=0)\n",
    "best_depth = np.mean(np.vstack((logreg_f1scs[:, 3], gnb_f1scs[:, 3], ada_f1scs[:,3], svc_f1scs[:, 3])).T, axis=0)\n",
    "\n",
    "# ... to take classifs(np.argmax(best_act)) for the best classifier name\n",
    "# But first test output\n",
    "idx_best_act = np.argmax(best_act)\n",
    "idx_best_acw = np.argmax(best_acw)\n",
    "idx_best_pressure = np.argmax(best_pressure)\n",
    "idx_best_depth = np.argmax(best_depth)\n",
    "\n",
    "print(f\"Best classifier for ACT : {classifs[idx_best_act]} with f1 : {best_act[idx_best_act]}\")\n",
    "print(f\"Best classifier for ACW : {classifs[idx_best_acw]} with f1 : {best_acw[idx_best_acw]}\")\n",
    "print(f\"Best classifier for Pressure mat : {classifs[idx_best_pressure]} with f1 : {best_pressure[idx_best_pressure]}\")\n",
    "print(f\"Best classifier for Depth Camera : {classifs[idx_best_depth]} with f1 : {best_depth[idx_best_depth]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task4'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Task 4.</b> (4 Points)\n",
    "\n",
    "Your final task is to predict the exercise in held out test set in mex_features_test_no_labels.csv file with the best strategy reported in Task 3. You can utilize the whole training data before making the predictions on the test set. Remember that the held out test set does not contain the subject or exercise IDs. Grading of this task is based solely on the performance in the held out test set. Include in your report your final score together with team name and screenshot of your result.\n",
    "\n",
    "## Instructions for submitting your predictions:\n",
    "\n",
    "Create an account at [project.mmdf.online](https://project.mmdf.online) and register your team name (you may use a pseudonym), but please do not include any special characters in the name. The top 10 leaderboard is public for everyone to see, but your individual submissions are visible only to you and the course teachers. Note that the website can only be accessed from the university network. If you are not on campus, you will need to connect through the university VPN; see the instructions [here](https://www.oulu.fi/en/for-students/supporting-your-studies-and-contact-information-for-students/it-services-for-students/remote-desktops).\n",
    "\n",
    "## Submission Format\n",
    "\n",
    "Your submission must be a **JSON file** ending with .json extension containing predictions for all **920 test samples** in the correct order.\n",
    "\n",
    "### Required Format\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"0\": 1,\n",
    "    \"1\": 3,\n",
    "    \"2\": 7,\n",
    "    \"3\": 2,\n",
    "    ...\n",
    "    \"919\": 5\n",
    "}\n",
    "```\n",
    "\n",
    "**Important requirements:**\n",
    "- Keys must be **strings**: `\"0\"`, `\"1\"`, `\"2\"`, ..., `\"919\"`\n",
    "- Values must be **integers** from **1 to 7** (exercise labels)\n",
    "- You must provide exactly **920 predictions** (one for each test sample)\n",
    "- Predictions must be in the **same order** as the test set\n",
    "- We provide an example submission file in example_submission.json. Additionally, the code block below shows how to convert a NumPy array into the required JSON submission format\n",
    "\n",
    "## Grading\n",
    "\n",
    "Your score for this task is determined solely by the F1-macro score on the held-out test set, according to the scale below:\n",
    "\n",
    "| F1-macro Score | Points Awarded |\n",
    "|----------------|----------------|\n",
    "| ‚â• 0.90         | 4              |\n",
    "| ‚â• 0.80         | 3              |\n",
    "| ‚â• 0.70         | 2              |\n",
    "| ‚â• 0.60         | 1              |\n",
    "| < 0.60         | 0              |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 1432)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHTNJREFUeJzt3QlwVeXdwOF/IBJcWARFSGXVugPuqXVDoSo4qCN1xRYrBe0oKoyjjeOG0xbqVqqlWjsK7Sh16SgqTrG4oiOo4DBWa6mhuFXQVgsRHCNKvjlnvqS5JKBg0rxJnmfmkNx7bm5OTm7CL+95z71F1dXV1QEAkJB2zb0BAAAbEigAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkpzhaoPXr18d7770XnTp1iqKioubeHADgK8ieG/bjjz+O0tLSaNeuXesLlCxOevfu3dybAQBsgXfeeSd23nnn1hco2chJzRfYuXPn5t4cAOArqKyszAcYav4fb3WBUnNYJ4sTgQIALctXmZ5hkiwAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkp7i5N4DG0e/Hj7a4Xfnm1OObexMASJQRFACg5QfK/PnzY+TIkVFaWhpFRUUxe/bsgvXZdQ0t119/fe1t+vXrV2/91KlTG+crAgDaXqCsXbs2Bg8eHNOnT29w/YoVKwqWO++8Mw+QUaNGFdzu2muvLbjdhAkTtvyrAADa9hyU4cOH58vG9OzZs+DyQw89FEcddVQMGDCg4PpOnTrVuy1AS2UeGLSgOSjvv/9+PProozF27Nh667JDOt27d4/99tsvP/zz+eefb/R+qqqqorKysmABAFqvJj2L53e/+10+UnLyyScXXH/hhRfG/vvvH926dYvnn38+ysvL88M8N910U4P3M2XKlJg8eXJTbioA0FYCJZt/Mnr06OjYsWPB9ZMmTap9f9CgQdGhQ4c499xz8xApKSmpdz9ZwNT9mGwEpXfv3k256QBAawyUZ599NpYuXRr33nvvl962rKwsP8Tz5ptvxu67715vfRYtDYULANA6NdkclDvuuCMOOOCA/IyfL7NkyZJo165d9OjRo6k2BwBozSMoa9asiYqKitrLy5cvzwMjm0/Sp0+f2kMw999/f9x44431Pn7BggXxwgsv5Gf2ZPNTsssTJ06Ms846K7bffvuv+/UAAG0xUBYtWpTHRY2auSFjxoyJmTNn5u/fc889UV1dHWeccUa9j88O1WTrr7nmmvzsnP79++eBUneOCQDQtm12oAwZMiSPj00ZP358vjQkO3tn4cKFm/tpAYA2xGvxAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQMsPlPnz58fIkSOjtLQ0ioqKYvbs2QXrzz777Pz6ustxxx1XcJuPPvooRo8eHZ07d46uXbvG2LFjY82aNV//qwEA2magrF27NgYPHhzTp0/f6G2yIFmxYkXt8oc//KFgfRYnr732WsybNy/mzJmTR8/48eO37CsAAFqd4s39gOHDh+fLppSUlETPnj0bXPf666/H3Llz46WXXooDDzwwv+6WW26JESNGxA033JCPzAAAbVuTzEF5+umno0ePHrH77rvHj370o/jwww9r1y1YsCA/rFMTJ5lhw4ZFu3bt4oUXXmiKzQEAWvsIypfJDu+cfPLJ0b9//1i2bFlcfvnl+YhLFibt27ePlStX5vFSsBHFxdGtW7d8XUOqqqrypUZlZWVjbzYA0JoD5fTTT699f+DAgTFo0KDYZZdd8lGVoUOHbtF9TpkyJSZPntyIWwkAtOnTjAcMGBA77LBDVFRU5JezuSkffPBBwW0+//zz/Myejc1bKS8vj9WrV9cu77zzTlNvNgDQmgPl3Xffzeeg9OrVK798yCGHxKpVq2Lx4sW1t3nyySdj/fr1UVZWttFJt9kpyXUXAKD12uxDPNnzldSMhmSWL18eS5YsyeeQZEt2KGbUqFH5aEg2B+XSSy+NXXfdNY499tj89nvuuWc+T2XcuHFx2223xbp16+KCCy7IDw05gwcA2KIRlEWLFsV+++2XL5lJkybl71911VX5JNhXXnklTjjhhNhtt93yJ2A74IAD4tlnn81HQWrcfffdsccee+RzUrLTiw877LC4/fbbfUcAgC0bQRkyZEhUV1dvdP1jjz32pfeRjbTMmjVrcz81ANBGNPpZPADAf/X78aMtcne8OfX4Zv38XiwQAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAklPc3BuQopb60tgA0FoYQQEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFACg5QfK/PnzY+TIkVFaWhpFRUUxe/bs2nXr1q2Lyy67LAYOHBjbbrttfpvvf//78d577xXcR79+/fKPrbtMnTq1cb4iAKDtBcratWtj8ODBMX369HrrPvnkk3j55ZfjyiuvzN8+8MADsXTp0jjhhBPq3fbaa6+NFStW1C4TJkzY8q8CAGhVijf3A4YPH54vDenSpUvMmzev4Lpf/epXcfDBB8fbb78dffr0qb2+U6dO0bNnzy3ZZgCglWvyOSirV6/OD+F07dq14PrskE737t1jv/32i+uvvz4+//zzjd5HVVVVVFZWFiwAQOu12SMom+PTTz/N56ScccYZ0blz59rrL7zwwth///2jW7du8fzzz0d5eXl+mOemm25q8H6mTJkSkydPbspNBQDaQqBkE2ZPPfXUqK6ujltvvbVg3aRJk2rfHzRoUHTo0CHOPffcPERKSkrq3VcWMHU/JhtB6d27d1NtOgDQGgOlJk7eeuutePLJJwtGTxpSVlaWH+J58803Y/fdd6+3PouWhsIFAGidipsqTt5444146qmn8nkmX2bJkiXRrl276NGjR2NvDgDQFgJlzZo1UVFRUXt5+fLleWBk80l69eoV3/3ud/NTjOfMmRNffPFFrFy5Mr9dtj47lLNgwYJ44YUX4qijjsrP5MkuT5w4Mc4666zYfvvtG/erAwDaRqAsWrQoj4saNXNDxowZE9dcc008/PDD+eV999234OOy0ZQhQ4bkh2ruueee/LbZ2Tn9+/fPA6XuHBMAoG3b7EDJIiOb+Loxm1qXyc7eWbhw4eZ+WgCgDfFaPABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHKKm3sDoCXp9+NHo6V5c+rxzb0JAJvNCAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQMsPlPnz58fIkSOjtLQ0ioqKYvbs2QXrq6ur46qrropevXrF1ltvHcOGDYs33nij4DYfffRRjB49Ojp37hxdu3aNsWPHxpo1a77+VwMAtM1AWbt2bQwePDimT5/e4Prrrrsubr755rjtttvihRdeiG233TaOPfbY+PTTT2tvk8XJa6+9FvPmzYs5c+bk0TN+/Piv95UAAK1G8eZ+wPDhw/OlIdnoybRp0+KKK66IE088Mb/u97//fey00075SMvpp58er7/+esydOzdeeumlOPDAA/Pb3HLLLTFixIi44YYb8pEZAKBta9Q5KMuXL4+VK1fmh3VqdOnSJcrKymLBggX55extdlinJk4y2e3btWuXj7gAAGz2CMqmZHGSyUZM6sou16zL3vbo0aNgfXFxcXTr1q32NhuqqqrKlxqVlZW+cwDQirWIs3imTJmSj8TULL17927uTQIAWkqg9OzZM3/7/vvvF1yfXa5Zl7394IMPCtZ//vnn+Zk9NbfZUHl5eaxevbp2eeeddxpzswGA1hwo/fv3zyPjiSeeKDgck80tOeSQQ/LL2dtVq1bF4sWLa2/z5JNPxvr16/O5Kg0pKSnJT0muuwAArddmz0HJnq+koqKiYGLskiVL8jkkffr0iYsvvjh+8pOfxDe/+c08WK688sr8zJyTTjopv/2ee+4Zxx13XIwbNy4/FXndunVxwQUX5Gf4OIMHANiiQFm0aFEcddRRtZcnTZqUvx0zZkzMnDkzLr300vy5UrLnNclGSg477LD8tOKOHTvWfszdd9+dR8nQoUPzs3dGjRqVP3cKAMAWBcqQIUPy5zvZmOzZZa+99tp82ZhstGXWrFm+AwBAyz2LBwBoWwQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJKe4uTcAAL6qfj9+1M5qI4ygAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkpbu4NANhQvx8/aqdAG2cEBQBo/YHSr1+/KCoqqrecf/75+fohQ4bUW3feeec19mYAAC1Yox/ieemll+KLL76ovfzqq6/Gd77znTjllFNqrxs3blxce+21tZe32Wabxt4MAKAFa/RA2XHHHQsuT506NXbZZZc48sgjC4KkZ8+ejf2pAYBWoknnoHz22Wdx1113xTnnnJMfyqlx9913xw477BD77LNPlJeXxyeffLLJ+6mqqorKysqCBQBovZr0LJ7Zs2fHqlWr4uyzz6697swzz4y+fftGaWlpvPLKK3HZZZfF0qVL44EHHtjo/UyZMiUmT57clJsKALSVQLnjjjti+PDheYzUGD9+fO37AwcOjF69esXQoUNj2bJl+aGghmSjLJMmTaq9nI2g9O7duyk3HQBojYHy1ltvxeOPP77JkZFMWVlZ/raiomKjgVJSUpIvAEDb0GRzUGbMmBE9evSI448/fpO3W7JkSf42G0kBAGiyEZT169fngTJmzJgoLv7vp8gO48yaNStGjBgR3bt3z+egTJw4MY444ogYNGiQ7wgA0HSBkh3aefvtt/Ozd+rq0KFDvm7atGmxdu3afB7JqFGj4oorrmiKzQAAWqgmCZRjjjkmqqur612fBckzzzzTFJ8SAGhFvBYPAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAtP5Aueaaa6KoqKhg2WOPPWrXf/rpp3H++edH9+7dY7vttotRo0bF+++/39ibAQC0YE0ygrL33nvHihUrapfnnnuudt3EiRPjkUceifvvvz+eeeaZeO+99+Lkk09uis0AAFqo4ia50+Li6NmzZ73rV69eHXfccUfMmjUrjj766Py6GTNmxJ577hkLFy6Mb33rW02xOQBAC9MkIyhvvPFGlJaWxoABA2L06NHx9ttv59cvXrw41q1bF8OGDau9bXb4p0+fPrFgwYKN3l9VVVVUVlYWLABA69XogVJWVhYzZ86MuXPnxq233hrLly+Pww8/PD7++ONYuXJldOjQIbp27VrwMTvttFO+bmOmTJkSXbp0qV169+7d2JsNALTmQzzDhw+vfX/QoEF5sPTt2zfuu+++2HrrrbfoPsvLy2PSpEm1l7MRFJECAK1Xk59mnI2W7LbbblFRUZHPS/nss89i1apVBbfJzuJpaM5KjZKSkujcuXPBAgC0Xk0eKGvWrIlly5ZFr1694oADDoitttoqnnjiidr1S5cuzeeoHHLIIU29KQBAWz3Ec8kll8TIkSPzwzrZKcRXX311tG/fPs4444x8/sjYsWPzwzXdunXLR0ImTJiQx4kzeACAJguUd999N4+RDz/8MHbcccc47LDD8lOIs/czv/jFL6Jdu3b5E7RlZ+cce+yx8etf/7qxNwMAaMEaPVDuueeeTa7v2LFjTJ8+PV8AABritXgAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAGj9gTJlypQ46KCDolOnTtGjR4846aSTYunSpQW3GTJkSBQVFRUs5513XmNvCgDQQjV6oDzzzDNx/vnnx8KFC2PevHmxbt26OOaYY2Lt2rUFtxs3blysWLGidrnuuusae1MAgBaquLHvcO7cuQWXZ86cmY+kLF68OI444oja67fZZpvo2bNnY396AKAVaPI5KKtXr87fduvWreD6u+++O3bYYYfYZ599ory8PD755JON3kdVVVVUVlYWLABA69XoIyh1rV+/Pi6++OI49NBD8xCpceaZZ0bfvn2jtLQ0XnnllbjsssvyeSoPPPDARue1TJ48uSk3FQBoK4GSzUV59dVX47nnniu4fvz48bXvDxw4MHr16hVDhw6NZcuWxS677FLvfrIRlkmTJtVezkZQevfu3ZSbDgC0xkC54IILYs6cOTF//vzYeeedN3nbsrKy/G1FRUWDgVJSUpIvAEDb0OiBUl1dHRMmTIgHH3wwnn766ejfv/+XfsySJUvyt9lICgBAcVMc1pk1a1Y89NBD+XOhrFy5Mr++S5cusfXWW+eHcbL1I0aMiO7du+dzUCZOnJif4TNo0CDfEQCg8QPl1ltvrX0ytrpmzJgRZ599dnTo0CEef/zxmDZtWv7cKNlcklGjRsUVV1zh2wEANN0hnk3JgiR7MjcAgI3xWjwAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQnGYNlOnTp0e/fv2iY8eOUVZWFi+++GJzbg4A0NYD5d57741JkybF1VdfHS+//HIMHjw4jj322Pjggw+aa5MAgLYeKDfddFOMGzcufvCDH8Ree+0Vt912W2yzzTZx5513NtcmAQCJKG6OT/rZZ5/F4sWLo7y8vPa6du3axbBhw2LBggX1bl9VVZUvNVavXp2/raysbJLtW1/1SZPcL4Wa6vvXlFriY8N+xmODVH531NxndXV1moHy73//O7744ovYaaedCq7PLv/tb3+rd/spU6bE5MmT613fu3fvJt1OmlaXafbw/4L9jMcGqf3u+Pjjj6NLly7pBcrmykZasvkqNdavXx8fffRRdO/ePYqKihq97rLweeedd6Jz586Net+tjX1lX3lc+RlsKfy+SmN/ZSMnWZyUlpZ+6W2bJVB22GGHaN++fbz//vsF12eXe/bsWe/2JSUl+VJX165dm3Qbs2+IQLGvPK6aj59B+8rjqnX+HH7ZyEmzTpLt0KFDHHDAAfHEE08UjIpklw855JDm2CQAICHNdognO2QzZsyYOPDAA+Pggw+OadOmxdq1a/OzegCAtq3ZAuW0006Lf/3rX3HVVVfFypUrY9999425c+fWmzj7v5YdSsqem2XDQ0rYVx5XfgZT4/eVfdWaH1tF1V/lXB8AgP8hr8UDACRHoAAAyREoAEByBAoAkByB8v/mz58fI0eOzJ/dLnt22tmzZzfvdyZR2csOHHTQQdGpU6fo0aNHnHTSSbF06dLm3qxk3XrrrTFo0KDaJzvKnufnT3/6U3NvVvKmTp2a/xxefPHFzb0pSbrmmmvy/VN32WOPPZp7s5L1z3/+M84666z82ce33nrrGDhwYCxatKi5Nys5/fr1q/e4ypbzzz+/WbZHoPy/7DlYBg8eHNOnT2+Wb0RL8cwzz+QP1oULF8a8efNi3bp1ccwxx+T7j/p23nnn/D/b7MUxs1+IRx99dJx44onx2muv2V0b8dJLL8VvfvObPOzYuL333jtWrFhRuzz33HN2VwP+85//xKGHHhpbbbVV/sfBX//617jxxhtj++23t78a+Nmr+5jKfsdnTjnllGgOLeK1eP4Xhg8fni9sWvZcNXXNnDkzH0nJ/gM+4ogj7L4NZKNydf30pz/NR1WywMv+g6HQmjVrYvTo0fHb3/42fvKTn9g9m1BcXNzgS4NQ6Oc//3n+mjIzZsyova5///52UwN23HHHgsvZH1e77LJLHHnkkdEcjKDwtaxevTp/261bN3vyS2Sv4H3PPffko01e0qFh2ejc8ccfH8OGDfN4+hJvvPFGfkh6wIABedS9/fbb9lkDHn744fwZy7NRgOyPqf322y8PYDbts88+i7vuuivOOeecRn9R3q/KCApbLHv9pGyOQDZ8us8++9iTG/GXv/wlD5JPP/00tttuu3jwwQdjr732sr82kMXbyy+/nA8zs2llZWX56OXuu++eD8VPnjw5Dj/88Hj11Vfz+WH81z/+8Y981DJ7eZXLL788f3xdeOGF+WvCZS+3QsOyeZirVq2Ks88+O5qLQOFr/bWb/UJ07HvTsv9ElixZko82/fGPf8x/KWZzeUTKf2Uv6X7RRRflx7w7duzop/JL1D0cnc3VyYKlb9++cd9998XYsWPtvw3+kMpGUH72s5/ll7MRlOz31m233SZQNuGOO+7IH2fZKF1zcYiHLXLBBRfEnDlz4qmnnsongrJx2V9qu+66a/4K3tlZUNlk7F/+8pd2WR3ZHKYPPvgg9t9//3xuRbZkEXfzzTfn72eHx9i4rl27xm677RYVFRV20wZ69epV74+BPffc0yGxTXjrrbfi8ccfjx/+8IfRnIygsFmyl26aMGFCfpji6aefNtlsC/+iq6qq8sirY+jQofmhsLqyVzbPTp297LLLon379vbXl0wuXrZsWXzve9+znzaQHYLe8KkQ/v73v+cjTjQsm1CczdfJ5oM1J4FS5we87l8fy5cvz4fls8mfffr0aa7vT5KHdWbNmhUPPfRQfqw7eyXqTJcuXfLnF6BQeXl5PkyaPYY+/vjjfN9lYffYY4/ZVXVkj6UN5zFtu+22+fNWmN9U3yWXXJKfIZb9J/vee+/lrzqbRdwZZ5zhcbWBiRMnxre//e38EM+pp54aL774Ytx+++35QsN/QGWBkh2KzkYvm1X2asZUVz/11FPZqzrXW8aMGWP31NHQPsqWGTNm2E8NOOecc6r79u1b3aFDh+odd9yxeujQodV//vOf7auv4Mgjj6y+6KKL7KsGnHbaadW9evXKH1ff+MY38ssVFRX21UY88sgj1fvss091SUlJ9R577FF9++2321cb8dhjj+W/05cuXVrd3Iqyf5o3kQAACpkkCwAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAEKn5P+vl3DBBjFh8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with hold-out test dataset : 123\n"
     ]
    }
   ],
   "source": [
    "# Implement your test set predicition in here\n",
    "\n",
    "df_test = pd.read_csv('mex_features_test_no_labels.csv')\n",
    "X_test = df_test.values\n",
    "#columns_to_drop = ['subject_id', 'exercise']\n",
    "#X_test = test_df.drop(columns=columns_to_drop, axis=1).values()\n",
    "print(X_test.shape)\n",
    "print(type(X_test))\n",
    "\n",
    "# Train best model\n",
    "mdl = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(kernel=\"linear\", class_weight=\"balanced\"))\n",
    "])\n",
    "mdl.fit(X_train, y_train)\n",
    "\n",
    "# Predict and score\n",
    "yhat = mdl.predict(X_test)\n",
    "f1_score = 123\n",
    "\n",
    "plt.hist(yhat)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions as json for submission\n",
    "import json\n",
    "\n",
    "# Convert to dictionary with string keys and Python ints\n",
    "# Assuming your predictions are in numpy array \"y_pred\"\n",
    "pred_dict = {str(i): int(y_pred[i]) for i in range(len(y_pred))}\n",
    "with open('submission.json', 'w') as f:\n",
    "    json.dump(pred_dict, f)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
